{"document":"Recursion_(computer_science)\nRecursive functions and algorithms\nA common algorithm design tactic is to divide a problem into sub-problems of the same type as the original, solve those sub-problems, and combine the results. This is often referred to as the divide-and-conquer method; when combined with a lookup table that stores the results of previously solved sub-problems (to avoid solving them repeatedly and incurring extra computation time), it can be referred to as dynamic programming or memoization.","icl_document":"Recursion and iteration are equally expressive: recursion can be replaced by iteration with an\nexplicit call stack, while iteration can be replaced with tail recursion. Which approach is\npreferable depends on the problem under consideration and the language used. In imperative\nprogramming, iteration is preferred, particularly for simple recursion, as it avoids the overhead\nof function calls and call stack management, but recursion is generally used for multiple recursion.\nBy contrast, in functional languages recursion is preferred, with tail recursion optimization leading\nto little overhead. Implementing an algorithm using iteration may not be easily achievable.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"Are recursion and iteration equally powerful?\n","icl_response_1":"Yes, recursion can be turned into iteration with a stack, and iteration into recursion.\n","icl_query_2":"When is iteration preferred over recursion?\n","icl_response_2":"In imperative languages for simple cases, to avoid function call overhead.\n","icl_query_3":"When is recursion preferred?\n","icl_response_3":"In functional languages or for complex problems like multiple recursion.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the name given to a common algorithm design tactic where a problem is divided into sub-problems of the same type and the results are combined to solve the original problem?\n\nA) Iterative Algorithm\nB) Divide-and-Conquer Algorithm\nC) Recursive Algorithm\nD) Memoization","mmlubench_answer":"B) Divide-and-Conquer Algorithm","dataset_type":"mcq_qa","answer":1,"choices":["Iterative Algorithm","Divide-and-Conquer Algorithm","Recursive Algorithm","Memoization"],"question":"What is the name given to a common algorithm design tactic where a problem is divided into sub-problems of the same type and the results are combined to solve the original problem?"}
{"document":"Recursion_(computer_science)\nRecursive functions and algorithms\nA common algorithm design tactic is to divide a problem into sub-problems of the same type as the original, solve those sub-problems, and combine the results. This is often referred to as the divide-and-conquer method; when combined with a lookup table that stores the results of previously solved sub-problems (to avoid solving them repeatedly and incurring extra computation time), it can be referred to as dynamic programming or memoization.","icl_document":"A classic example of a recursive procedure is the function used to calculate the factorial of a\nnatural number:\nfact(n) = { 1 if n=0; n \u00b7 fact(n-1) if n>0 }\nThe function can also be written as a recurrence relation:\nb_n = n b_{n-1}\nb_0 = 1\nThis factorial function can also be described without using recursion by making use of the typical\nlooping constructs found in imperative programming languages.\nThe imperative code is equivalent to a mathematical definition using an accumulator variable.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"How is factorial defined recursively?\n","icl_response_1":"fact(n) = 1 if n=0, else n * fact(n-1).\n","icl_query_2":"What is the base case in factorial?\n","icl_response_2":"When n=0, fact(0)=1.\n","icl_query_3":"Can factorial be done without recursion?\n","icl_response_3":"Yes, using loops in imperative languages.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the common algorithm design tactic described in the document?\n\nA) Iterative programming\nB) Divide-and-conquer method\nC) Memoization\nD) Recursive functions","mmlubench_answer":"D) Recursive functions","dataset_type":"mcq_qa","answer":3,"choices":["Iterative programming","Divide-and-conquer method","Memoization","Recursive functions"],"question":"What is the common algorithm design tactic described in the document?"}
{"document":"Recursion_(computer_science)\nRecursive functions and algorithms\nA common algorithm design tactic is to divide a problem into sub-problems of the same type as the original, solve those sub-problems, and combine the results. This is often referred to as the divide-and-conquer method; when combined with a lookup table that stores the results of previously solved sub-problems (to avoid solving them repeatedly and incurring extra computation time), it can be referred to as dynamic programming or memoization.","icl_document":"A classic example of a recursive procedure is the function used to calculate the factorial of a\nnatural number:\nfact(n) = { 1 if n=0; n \u00b7 fact(n-1) if n>0 }\nThe function can also be written as a recurrence relation:\nb_n = n b_{n-1}\nb_0 = 1\nThis factorial function can also be described without using recursion by making use of the typical\nlooping constructs found in imperative programming languages.\nThe imperative code is equivalent to a mathematical definition using an accumulator variable.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"How is factorial defined recursively?\n","icl_response_1":"fact(n) = 1 if n=0, else n * fact(n-1).\n","icl_query_2":"What is the base case in factorial?\n","icl_response_2":"When n=0, fact(0)=1.\n","icl_query_3":"Can factorial be done without recursion?\n","icl_response_3":"Yes, using loops in imperative languages.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"Which algorithm design tactic does the document discuss, involving the division of a problem into sub-problems of the same type and solving those sub-problems?\n\nA) Dynamic programming\nB) Memoization\nC) Divide-and-conquer method\nD) Recursive functions","mmlubench_answer":"C) Divide-and-conquer method","dataset_type":"mcq_qa","answer":2,"choices":["Dynamic programming","Memoization","Divide-and-conquer method","Recursive functions"],"question":"Which algorithm design tactic does the document discuss, involving the division of a problem into sub-problems of the same type and solving those sub-problems?"}
{"document":"Recursion_(computer_science)\nRecursive functions and algorithms\nA common algorithm design tactic is to divide a problem into sub-problems of the same type as the original, solve those sub-problems, and combine the results. This is often referred to as the divide-and-conquer method; when combined with a lookup table that stores the results of previously solved sub-problems (to avoid solving them repeatedly and incurring extra computation time), it can be referred to as dynamic programming or memoization.","icl_document":"A classic example of a recursive procedure is the function used to calculate the factorial of a\nnatural number:\nfact(n) = { 1 if n=0; n \u00b7 fact(n-1) if n>0 }\nThe function can also be written as a recurrence relation:\nb_n = n b_{n-1}\nb_0 = 1\nThis factorial function can also be described without using recursion by making use of the typical\nlooping constructs found in imperative programming languages.\nThe imperative code is equivalent to a mathematical definition using an accumulator variable.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"How is factorial defined recursively?\n","icl_response_1":"fact(n) = 1 if n=0, else n * fact(n-1).\n","icl_query_2":"What is the base case in factorial?\n","icl_response_2":"When n=0, fact(0)=1.\n","icl_query_3":"Can factorial be done without recursion?\n","icl_response_3":"Yes, using loops in imperative languages.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What term is used to describe the combination of dynamic programming or memoization with recursive functions?\n\nA) Dynamic recursion\nB) Memoized recursion\nC) Recursive programming\nD) Divide-and-conquer algorithm","mmlubench_answer":"A) Dynamic recursion","dataset_type":"mcq_qa","answer":0,"choices":["Dynamic recursion","Memoized recursion","Recursive programming","Divide-and-conquer algorithm"],"question":"What term is used to describe the combination of dynamic programming or memoization with recursive functions?"}
{"document":"Recursion_(computer_science)\nRecursive data types\nMany computer programs must process or generate an arbitrarily large quantity of data.  Recursion is a technique for representing data whose exact size is unknown to the programmer: the programmer can specify this data with a self-referential definition.  There are two types of self-referential definitions: inductive and coinductive definitions.","icl_document":"In computer science, recursion is a method of solving a computational problem where the solution\ndepends on solutions to smaller instances of the same problem. Recursion solves such recursive\nproblems by using functions that call themselves from within their own code. The approach can be\napplied to many types of problems, and recursion is one of the central ideas of computer science.\nThe power of recursion evidently lies in the possibility of defining an infinite set of objects\nby a finite statement. In the same manner, an infinite number of computations can be described by\na finite recursive program, even if this program contains no explicit repetitions\nMost computer programming languages support recursion by allowing a function to call itself from\nwithin its own code. Some functional programming languages (for instance, Clojure) do not define\nany looping constructs but rely solely on recursion to repeatedly call code. It is proved in\ncomputability theory that these recursive-only languages are Turing complete; this means that\nthey are as powerful (they can be used to solve the same problems) as imperative languages based\non control structures such as while and for.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is recursion in computer science?\n","icl_response_1":"Recursion is a method where a function calls itself to solve a problem by breaking it into\nsmaller instances of the same problem.\n","icl_query_2":"Why is recursion powerful?\n","icl_response_2":"It allows defining infinite computations or objects with a finite statement, without explicit\nrepetitions.\n","icl_query_3":"Do most programming languages support recursion?\n","icl_response_3":"Yes, most allow functions to call themselves, and some rely solely on recursion instead of loops.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is recursion in computer science and what type of data does it represent?\n\nA) A technique for solving complex problems iteratively\nB) A method for defining data whose size is known to the programmer\nC) A self-referential definition for handling unknown or arbitrarily large data\nD) A programming concept used for generating data in a top-down manner","mmlubench_answer":"C) A self-referential definition for handling unknown or arbitrarily large data","dataset_type":"mcq_qa","answer":2,"choices":["A technique for solving complex problems iteratively","A method for defining data whose size is known to the programmer","A self-referential definition for handling unknown or arbitrarily large data","A programming concept used for generating data in a top-down manner"],"question":"What is recursion in computer science and what type of data does it represent?"}
{"document":"Recursion_(computer_science)\nRecursive data types\nCoinductively defined data and corecursion\nA coinductive data definition is one that specifies the operations that may be performed on a piece of data; typically, self-referential coinductive definitions are used for data structures of infinite size.\nA coinductive definition of infinite streams of strings, given informally, might look like this:\nA stream of strings is an object s such that:\nhead(s) is a string, and\ntail(s) is a stream of strings.\nThis is very similar to an inductive definition of lists of strings; the difference is that this definition specifies how to access the contents of the data structure\u2014namely, via the accessor functions head and tail\u2014and what those contents may be, whereas the inductive definition specifies how to create the structure and what it may be created from.\nCorecursion is related to coinduction, and can be used to compute particular instances of (possibly) infinite objects.  As a programming technique, it is used most often in the context of lazy programming languages, and can be preferable to recursion when the desired size or precision of a program's output is unknown.  In such cases the program requires both a definition for an infinitely large (or infinitely precise) result, and a mechanism for taking a finite portion of that result.  The problem of computing the first n prime numbers is one that can be solved with a corecursive program (e.g. here).","icl_document":"In computer science, recursion is a method of solving a computational problem where the solution\ndepends on solutions to smaller instances of the same problem. Recursion solves such recursive\nproblems by using functions that call themselves from within their own code. The approach can be\napplied to many types of problems, and recursion is one of the central ideas of computer science.\nThe power of recursion evidently lies in the possibility of defining an infinite set of objects\nby a finite statement. In the same manner, an infinite number of computations can be described by\na finite recursive program, even if this program contains no explicit repetitions\nMost computer programming languages support recursion by allowing a function to call itself from\nwithin its own code. Some functional programming languages (for instance, Clojure) do not define\nany looping constructs but rely solely on recursion to repeatedly call code. It is proved in\ncomputability theory that these recursive-only languages are Turing complete; this means that\nthey are as powerful (they can be used to solve the same problems) as imperative languages based\non control structures such as while and for.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is recursion in computer science?\n","icl_response_1":"Recursion is a method where a function calls itself to solve a problem by breaking it into\nsmaller instances of the same problem.\n","icl_query_2":"Why is recursion powerful?\n","icl_response_2":"It allows defining infinite computations or objects with a finite statement, without explicit\nrepetitions.\n","icl_query_3":"Do most programming languages support recursion?\n","icl_response_3":"Yes, most allow functions to call themselves, and some rely solely on recursion instead of loops.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the difference between an inductive and a coinductive data definition?\n\nA) An inductive definition specifies how to create a data structure, while a coinductive definition specifies how to access its contents.\nB) A coinductive definition is used for finite data structures, while an inductive definition is used for infinite ones.\nC) An inductive definition defines the operations that can be performed on a piece of data, while a coinductive definition does not.\nD) A coinductive definition is a programming technique used only in lazy programming languages.","mmlubench_answer":"C) An inductive definition defines the operations that can be performed on a piece of data, while a coinductive definition specifies how to access its contents.","dataset_type":"mcq_qa","answer":2,"choices":["An inductive definition specifies how to create a data structure, while a coinductive definition specifies how to access its contents.","A coinductive definition is used for finite data structures, while an inductive definition is used for infinite ones.","An inductive definition defines the operations that can be performed on a piece of data, while a coinductive definition does not.","A coinductive definition is a programming technique used only in lazy programming languages."],"question":"What is the difference between an inductive and a coinductive data definition?"}
{"document":"Recursion_(computer_science)\nRecursive data types\nCoinductively defined data and corecursion\nA coinductive data definition is one that specifies the operations that may be performed on a piece of data; typically, self-referential coinductive definitions are used for data structures of infinite size.\nA coinductive definition of infinite streams of strings, given informally, might look like this:\nA stream of strings is an object s such that:\nhead(s) is a string, and\ntail(s) is a stream of strings.\nThis is very similar to an inductive definition of lists of strings; the difference is that this definition specifies how to access the contents of the data structure\u2014namely, via the accessor functions head and tail\u2014and what those contents may be, whereas the inductive definition specifies how to create the structure and what it may be created from.\nCorecursion is related to coinduction, and can be used to compute particular instances of (possibly) infinite objects.  As a programming technique, it is used most often in the context of lazy programming languages, and can be preferable to recursion when the desired size or precision of a program's output is unknown.  In such cases the program requires both a definition for an infinitely large (or infinitely precise) result, and a mechanism for taking a finite portion of that result.  The problem of computing the first n prime numbers is one that can be solved with a corecursive program (e.g. here).","icl_document":"Recursion that contains only a single self-reference is known as single recursion, while recursion\nthat contains multiple self-references is known as multiple recursion. Standard examples of single\nrecursion include list traversal, such as in a linear search, or computing the factorial function,\nwhile standard examples of multiple recursion include tree traversal, such as in a depth-first\nsearch.\nSingle recursion is often much more efficient than multiple recursion, and can generally be replaced\nby an iterative computation, running in linear time and requiring constant space. Multiple recursion,\nby contrast, may require exponential time and space, and is more fundamentally recursive, not being\nable to be replaced by iteration without an explicit stack.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is single recursion?\n","icl_response_1":"It's recursion with only one self-reference, like in factorial or linear search.\n","icl_query_2":"What is multiple recursion?\n","icl_response_2":"It's recursion with multiple self-references, like in tree traversal or depth-first search.\n","icl_query_3":"How do single and multiple recursion differ in efficiency?\n","icl_response_3":"Single is often more efficient and can be iterative; multiple may need more time and space.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the difference between an inductive definition and a coinductive definition in computer science?\n\nA) An inductive definition specifies how to access the contents of a data structure, while a coinductive definition specifies how to create the structure.\nB) A coinductive definition specifies how to create the structure, while an inductive definition specifies how to access the contents.\nC) An inductive definition is used for finite data structures, while a coinductive definition is used for infinite data structures.\nD) A coinductive definition is used for creating data structures in imperative programming languages, while an inductive definition is used for functional programming.","mmlubench_answer":"A) An inductive definition specifies how to create the structure and what it may be created from, while a coinductive definition specifies how to access the contents and what those contents may be.","dataset_type":"mcq_qa","answer":0,"choices":["An inductive definition specifies how to access the contents of a data structure, while a coinductive definition specifies how to create the structure.","A coinductive definition specifies how to create the structure, while an inductive definition specifies how to access the contents.","An inductive definition is used for finite data structures, while a coinductive definition is used for infinite data structures.","A coinductive definition is used for creating data structures in imperative programming languages, while an inductive definition is used for functional programming."],"question":"What is the difference between an inductive definition and a coinductive definition in computer science?"}
{"document":"Recursion_(computer_science)\nRecursive data types\nCoinductively defined data and corecursion\nA coinductive data definition is one that specifies the operations that may be performed on a piece of data; typically, self-referential coinductive definitions are used for data structures of infinite size.\nA coinductive definition of infinite streams of strings, given informally, might look like this:\nA stream of strings is an object s such that:\nhead(s) is a string, and\ntail(s) is a stream of strings.\nThis is very similar to an inductive definition of lists of strings; the difference is that this definition specifies how to access the contents of the data structure\u2014namely, via the accessor functions head and tail\u2014and what those contents may be, whereas the inductive definition specifies how to create the structure and what it may be created from.\nCorecursion is related to coinduction, and can be used to compute particular instances of (possibly) infinite objects.  As a programming technique, it is used most often in the context of lazy programming languages, and can be preferable to recursion when the desired size or precision of a program's output is unknown.  In such cases the program requires both a definition for an infinitely large (or infinitely precise) result, and a mechanism for taking a finite portion of that result.  The problem of computing the first n prime numbers is one that can be solved with a corecursive program (e.g. here).","icl_document":"Recursion and iteration are equally expressive: recursion can be replaced by iteration with an\nexplicit call stack, while iteration can be replaced with tail recursion. Which approach is\npreferable depends on the problem under consideration and the language used. In imperative\nprogramming, iteration is preferred, particularly for simple recursion, as it avoids the overhead\nof function calls and call stack management, but recursion is generally used for multiple recursion.\nBy contrast, in functional languages recursion is preferred, with tail recursion optimization leading\nto little overhead. Implementing an algorithm using iteration may not be easily achievable.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"Are recursion and iteration equally powerful?\n","icl_response_1":"Yes, recursion can be turned into iteration with a stack, and iteration into recursion.\n","icl_query_2":"When is iteration preferred over recursion?\n","icl_response_2":"In imperative languages for simple cases, to avoid function call overhead.\n","icl_query_3":"When is recursion preferred?\n","icl_response_3":"In functional languages or for complex problems like multiple recursion.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is a coinductive data definition, and how does it differ from an inductive definition?\n\nA) A coinductive data definition specifies the operations that can be performed on a piece of data, while an inductive definition specifies how to create the structure.\nB) A coinductive data definition allows for self-referential definitions, while an inductive definition does not.\nC) A coinductive data definition is used only in the context of finite objects, while an inductive definition can be used for both finite and infinite objects.\nD) A coinductive data definition is a new type of data definition not related to inductive or recursive definitions.","mmlubench_answer":"A) A coinductive data definition specifies the operations that can be performed on a piece of data, while an inductive definition specifies how to create the structure.","dataset_type":"mcq_qa","answer":0,"choices":["A coinductive data definition specifies the operations that can be performed on a piece of data, while an inductive definition specifies how to create the structure.","A coinductive data definition allows for self-referential definitions, while an inductive definition does not.","A coinductive data definition is used only in the context of finite objects, while an inductive definition can be used for both finite and infinite objects.","A coinductive data definition is a new type of data definition not related to inductive or recursive definitions."],"question":"What is a coinductive data definition, and how does it differ from an inductive definition?"}
{"document":"Recursion_(computer_science)\nRecursive data types\nCoinductively defined data and corecursion\nA coinductive data definition is one that specifies the operations that may be performed on a piece of data; typically, self-referential coinductive definitions are used for data structures of infinite size.\nA coinductive definition of infinite streams of strings, given informally, might look like this:\nA stream of strings is an object s such that:\nhead(s) is a string, and\ntail(s) is a stream of strings.\nThis is very similar to an inductive definition of lists of strings; the difference is that this definition specifies how to access the contents of the data structure\u2014namely, via the accessor functions head and tail\u2014and what those contents may be, whereas the inductive definition specifies how to create the structure and what it may be created from.\nCorecursion is related to coinduction, and can be used to compute particular instances of (possibly) infinite objects.  As a programming technique, it is used most often in the context of lazy programming languages, and can be preferable to recursion when the desired size or precision of a program's output is unknown.  In such cases the program requires both a definition for an infinitely large (or infinitely precise) result, and a mechanism for taking a finite portion of that result.  The problem of computing the first n prime numbers is one that can be solved with a corecursive program (e.g. here).","icl_document":"Recursion and iteration are equally expressive: recursion can be replaced by iteration with an\nexplicit call stack, while iteration can be replaced with tail recursion. Which approach is\npreferable depends on the problem under consideration and the language used. In imperative\nprogramming, iteration is preferred, particularly for simple recursion, as it avoids the overhead\nof function calls and call stack management, but recursion is generally used for multiple recursion.\nBy contrast, in functional languages recursion is preferred, with tail recursion optimization leading\nto little overhead. Implementing an algorithm using iteration may not be easily achievable.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"Are recursion and iteration equally powerful?\n","icl_response_1":"Yes, recursion can be turned into iteration with a stack, and iteration into recursion.\n","icl_query_2":"When is iteration preferred over recursion?\n","icl_response_2":"In imperative languages for simple cases, to avoid function call overhead.\n","icl_query_3":"When is recursion preferred?\n","icl_response_3":"In functional languages or for complex problems like multiple recursion.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is corecursion and when is it used?\n\nA) Corecursion is a programming technique used to define infinitely large or precise results in lazy programming languages. It is used when the desired size or precision of a program's output is unknown.\nB) Corecursion is a type of recursion that can be used only for finite data structures.\nC) Corecursion is a method for computing the first n prime numbers.\nD) Corecursion is a new programming concept not related to recursion or coinduction.","mmlubench_answer":"A) Corecursion is a programming technique used to define infinitely large or precise results in lazy programming languages. It is used when the desired size or precision of a program's output is unknown.","dataset_type":"mcq_qa","answer":0,"choices":["Corecursion is a programming technique used to define infinitely large or precise results in lazy programming languages. It is used when the desired size or precision of a program's output is unknown.","Corecursion is a type of recursion that can be used only for finite data structures.","Corecursion is a method for computing the first n prime numbers.","Corecursion is a new programming concept not related to recursion or coinduction."],"question":"What is corecursion and when is it used?"}
{"document":"Recursion_(computer_science)\nRecursive data types\nCoinductively defined data and corecursion\nA coinductive data definition is one that specifies the operations that may be performed on a piece of data; typically, self-referential coinductive definitions are used for data structures of infinite size.\nA coinductive definition of infinite streams of strings, given informally, might look like this:\nA stream of strings is an object s such that:\nhead(s) is a string, and\ntail(s) is a stream of strings.\nThis is very similar to an inductive definition of lists of strings; the difference is that this definition specifies how to access the contents of the data structure\u2014namely, via the accessor functions head and tail\u2014and what those contents may be, whereas the inductive definition specifies how to create the structure and what it may be created from.\nCorecursion is related to coinduction, and can be used to compute particular instances of (possibly) infinite objects.  As a programming technique, it is used most often in the context of lazy programming languages, and can be preferable to recursion when the desired size or precision of a program's output is unknown.  In such cases the program requires both a definition for an infinitely large (or infinitely precise) result, and a mechanism for taking a finite portion of that result.  The problem of computing the first n prime numbers is one that can be solved with a corecursive program (e.g. here).","icl_document":"A classic example of a recursive procedure is the function used to calculate the factorial of a\nnatural number:\nfact(n) = { 1 if n=0; n \u00b7 fact(n-1) if n>0 }\nThe function can also be written as a recurrence relation:\nb_n = n b_{n-1}\nb_0 = 1\nThis factorial function can also be described without using recursion by making use of the typical\nlooping constructs found in imperative programming languages.\nThe imperative code is equivalent to a mathematical definition using an accumulator variable.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"How is factorial defined recursively?\n","icl_response_1":"fact(n) = 1 if n=0, else n * fact(n-1).\n","icl_query_2":"What is the base case in factorial?\n","icl_response_2":"When n=0, fact(0)=1.\n","icl_query_3":"Can factorial be done without recursion?\n","icl_response_3":"Yes, using loops in imperative languages.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the difference between an inductive and a coinductive data definition?\n\nA) An inductive definition specifies how to create a data structure, while a coinductive definition specifies how to access its contents.\nB) An inductive definition specifies how to access a data structure's contents, while a coinductive definition specifies how to create it.\nC) An inductive definition is used for finite data structures, while a coinductive definition is used for infinite ones.\nD) A coinductive definition is a type of recursive definition that can be used for data structures of unknown size or precision.","mmlubench_answer":"D) A coinductive definition is a type of recursive definition that can be used for data structures of unknown size or precision.","dataset_type":"mcq_qa","answer":3,"choices":["An inductive definition specifies how to create a data structure, while a coinductive definition specifies how to access its contents.","An inductive definition specifies how to access a data structure's contents, while a coinductive definition specifies how to create it.","An inductive definition is used for finite data structures, while a coinductive definition is used for infinite ones.","A coinductive definition is a type of recursive definition that can be used for data structures of unknown size or precision."],"question":"What is the difference between an inductive and a coinductive data definition?"}
{"document":"Recursion_(computer_science)\nTypes of recursion\nSingle recursion and multiple recursion\nRecursion that contains only a single self-reference is known as single recursion, while recursion that contains multiple self-references is known as multiple recursion. Standard examples of single recursion include list traversal, such as in a linear search, or computing the factorial function, while standard examples of multiple recursion include tree traversal, such as in a depth-first search.\nSingle recursion is often much more efficient than multiple recursion, and can generally be replaced by an iterative computation, running in linear time and requiring constant space. Multiple recursion, by contrast, may require exponential time and space, and is more fundamentally recursive, not being able to be replaced by iteration without an explicit stack.\nMultiple recursion can sometimes be converted to single recursion (and, if desired, thence to iteration). For example, while computing the Fibonacci sequence naively entails multiple iteration, as each value requires two previous values, it can be computed by single recursion by passing two successive values as parameters. This is more naturally framed as corecursion, building up from the initial values, while tracking two successive values at each step \u2013 see corecursion: examples. A more sophisticated example involves using a threaded binary tree, which allows iterative tree traversal, rather than multiple recursion.","icl_document":"In computer science, recursion is a method of solving a computational problem where the solution\ndepends on solutions to smaller instances of the same problem. Recursion solves such recursive\nproblems by using functions that call themselves from within their own code. The approach can be\napplied to many types of problems, and recursion is one of the central ideas of computer science.\nThe power of recursion evidently lies in the possibility of defining an infinite set of objects\nby a finite statement. In the same manner, an infinite number of computations can be described by\na finite recursive program, even if this program contains no explicit repetitions\nMost computer programming languages support recursion by allowing a function to call itself from\nwithin its own code. Some functional programming languages (for instance, Clojure) do not define\nany looping constructs but rely solely on recursion to repeatedly call code. It is proved in\ncomputability theory that these recursive-only languages are Turing complete; this means that\nthey are as powerful (they can be used to solve the same problems) as imperative languages based\non control structures such as while and for.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is recursion in computer science?\n","icl_response_1":"Recursion is a method where a function calls itself to solve a problem by breaking it into\nsmaller instances of the same problem.\n","icl_query_2":"Why is recursion powerful?\n","icl_response_2":"It allows defining infinite computations or objects with a finite statement, without explicit\nrepetitions.\n","icl_query_3":"Do most programming languages support recursion?\n","icl_response_3":"Yes, most allow functions to call themselves, and some rely solely on recursion instead of loops.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the main difference between single recursion and multiple recursion in computer science?\n\nA) Single recursion can only be used for list traversals, while multiple recursion is used for tree traversals.\nB) Single recursion requires constant space, while multiple recursion may require exponential space.\nC) Single recursion is generally more efficient than multiple recursion.\nD) Multiple recursion can always be replaced by single recursion.","mmlubench_answer":"C) Single recursion is generally more efficient than multiple recursion.","dataset_type":"mcq_qa","answer":2,"choices":["Single recursion can only be used for list traversals, while multiple recursion is used for tree traversals.","Single recursion requires constant space, while multiple recursion may require exponential space.","Single recursion is generally more efficient than multiple recursion.","Multiple recursion can always be replaced by single recursion."],"question":"What is the main difference between single recursion and multiple recursion in computer science?"}
{"document":"Recursion_(computer_science)\nTypes of recursion\nAnonymous recursion\nRecursion is usually done by explicitly calling a function by name. However, recursion can also be done via implicitly calling a function based on the current context, which is particularly useful for anonymous functions, and is known as anonymous recursion.","icl_document":"In computer science, recursion is a method of solving a computational problem where the solution\ndepends on solutions to smaller instances of the same problem. Recursion solves such recursive\nproblems by using functions that call themselves from within their own code. The approach can be\napplied to many types of problems, and recursion is one of the central ideas of computer science.\nThe power of recursion evidently lies in the possibility of defining an infinite set of objects\nby a finite statement. In the same manner, an infinite number of computations can be described by\na finite recursive program, even if this program contains no explicit repetitions\nMost computer programming languages support recursion by allowing a function to call itself from\nwithin its own code. Some functional programming languages (for instance, Clojure) do not define\nany looping constructs but rely solely on recursion to repeatedly call code. It is proved in\ncomputability theory that these recursive-only languages are Turing complete; this means that\nthey are as powerful (they can be used to solve the same problems) as imperative languages based\non control structures such as while and for.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is recursion in computer science?\n","icl_response_1":"Recursion is a method where a function calls itself to solve a problem by breaking it into\nsmaller instances of the same problem.\n","icl_query_2":"Why is recursion powerful?\n","icl_response_2":"It allows defining infinite computations or objects with a finite statement, without explicit\nrepetitions.\n","icl_query_3":"Do most programming languages support recursion?\n","icl_response_3":"Yes, most allow functions to call themselves, and some rely solely on recursion instead of loops.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the term used for recursion done implicitly based on the current context, particularly useful for anonymous functions?\n\nA) Explicit recursion\nB) Named recursion\nC) Anonymous recursion\nD) Functional recursion","mmlubench_answer":"C) Anonymous recursion","dataset_type":"mcq_qa","answer":2,"choices":["Explicit recursion","Named recursion","Anonymous recursion","Functional recursion"],"question":"What is the term used for recursion done implicitly based on the current context, particularly useful for anonymous functions?"}
{"document":"Recursion_(computer_science)\nTypes of recursion\nAnonymous recursion\nRecursion is usually done by explicitly calling a function by name. However, recursion can also be done via implicitly calling a function based on the current context, which is particularly useful for anonymous functions, and is known as anonymous recursion.","icl_document":"A recursive function definition has one or more base cases, meaning input(s) for which the\nfunction produces a result trivially (without recurring), and one or more recursive cases, meaning\ninput(s) for which the program recurs (calls itself). For example, the factorial function can be\ndefined recursively by the equations 0! = 1 and, for all n > 0, n! = n(n - 1)!. Neither equation by\nitself constitutes a complete definition; the first is the base case, and the second is the\nrecursive case. Because the base case breaks the chain of recursion, it is sometimes also called\nthe \"terminating case\".\nThe job of the recursive cases can be seen as breaking down complex inputs into simpler ones. In a\nproperly designed recursive function, with each recursive call, the input problem must be simplified\nin such a way that eventually the base case must be reached. Neglecting to write a base case, or\ntesting for it incorrectly, can cause an infinite loop.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is a base case in a recursive function?\n","icl_response_1":"It's the input where the function returns a result without calling itself, like 0! = 1 in factorial.\n","icl_query_2":"What happens in the recursive case?\n","icl_response_2":"The function calls itself with a simpler input, breaking down the problem until the base case is\nreached.\n","icl_query_3":"Why is the base case important?\n","icl_response_3":"It stops the recursion; without it, the function might cause an infinite loop.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is Anonymous Recursion in the context of computer science?\n\nA) A type of recursion where a function calls itself using an explicit name\nB) A type of recursion where a function calls itself using an implicit context, useful for anonymous functions\nC) A type of recursion where a function calls another function multiple times within its own definition\nD) A type of recursion where a function calls itself repeatedly with decreasing arguments until a base case is reached","mmlubench_answer":"B) A type of recursion where a function calls itself using an implicit context, useful for anonymous functions.","dataset_type":"mcq_qa","answer":1,"choices":["A type of recursion where a function calls itself using an explicit name","A type of recursion where a function calls itself using an implicit context, useful for anonymous functions","A type of recursion where a function calls another function multiple times within its own definition","A type of recursion where a function calls itself repeatedly with decreasing arguments until a base case is reached"],"question":"What is Anonymous Recursion in the context of computer science?"}
{"document":"Recursion_(computer_science)\nTypes of recursion\nStructural versus generative recursion\nSome authors classify recursion as either \"structural\" or \"generative\".  The distinction is related to where a recursive procedure gets the data that it works on, and how it processes that data:\n[Functions that consume structured data] typically decompose their arguments into their immediate structural components and then process those components. If one of the immediate components belongs to the same class of data as the input, the function is recursive. For that reason, we refer to these functions as (STRUCTURALLY) RECURSIVE  FUNCTIONS.\nThus, the defining characteristic of a structurally recursive function is that the argument to each recursive call is the content of a field of the original input.  Structural recursion includes nearly all tree traversals, including XML processing, binary tree creation and search, etc. By considering the algebraic structure of the natural numbers (that is, a natural number is either zero or the successor of a natural number), functions such as factorial may also be regarded as structural recursion.\nGenerative recursion is the alternative:\nMany well-known recursive algorithms generate an entirely new piece of data from the given data and recur on it.  HtDP (How to Design Programs) refers to this kind as generative recursion.  Examples of generative recursion include: gcd, quicksort, binary search, mergesort, Newton's method, fractals, and adaptive integration.\nThis distinction is important in proving termination of a function.","icl_document":"A classic example of a recursive procedure is the function used to calculate the factorial of a\nnatural number:\nfact(n) = { 1 if n=0; n \u00b7 fact(n-1) if n>0 }\nThe function can also be written as a recurrence relation:\nb_n = n b_{n-1}\nb_0 = 1\nThis factorial function can also be described without using recursion by making use of the typical\nlooping constructs found in imperative programming languages.\nThe imperative code is equivalent to a mathematical definition using an accumulator variable.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"How is factorial defined recursively?\n","icl_response_1":"fact(n) = 1 if n=0, else n * fact(n-1).\n","icl_query_2":"What is the base case in factorial?\n","icl_response_2":"When n=0, fact(0)=1.\n","icl_query_3":"Can factorial be done without recursion?\n","icl_response_3":"Yes, using loops in imperative languages.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"Which type of recursion is defined as getting data from the immediate structural components of the input and processing them?\n\nA) Generative Recursion\nB) Structural Recursion\nC) Depth-First Recursion\nD) Breadth-First Recursion","mmlubench_answer":"B) Structural Recursion","dataset_type":"mcq_qa","answer":1,"choices":["Generative Recursion","Structural Recursion","Depth-First Recursion","Breadth-First Recursion"],"question":"Which type of recursion is defined as getting data from the immediate structural components of the input and processing them?"}
{"document":"Recursion_(computer_science)\nImplementation issues\nShort-circuiting the base case\n=### Depth-first search=\nA basic example of short-circuiting is given in depth-first search (DFS) of a binary tree; see binary trees section for standard recursive discussion.\nThe standard recursive algorithm for a DFS is:\nbase case: If current node is Null, return false\nrecursive step: otherwise, check value of current node, return true if match, otherwise recurse on children\nIn short-circuiting, this is instead:\ncheck value of current node, return true if match,\notherwise, on children, if not Null, then recurse.\nIn terms of the standard steps, this moves the base case check before the recursive step. Alternatively, these can be considered a different form of base case and recursive step, respectively. Note that this requires a wrapper function to handle the case when the tree itself is empty (root node is Null).\nIn the case of a perfect binary tree of height h, there are 2h+1\u22121 nodes and 2h+1 Null pointers as children (2 for each of the 2h leaves), so short-circuiting cuts the number of function calls in half in the worst case.\nIn C, the standard recursive algorithm may be implemented as:\nThe short-circuited algorithm may be implemented as:","icl_document":"A recursive function definition has one or more base cases, meaning input(s) for which the\nfunction produces a result trivially (without recurring), and one or more recursive cases, meaning\ninput(s) for which the program recurs (calls itself). For example, the factorial function can be\ndefined recursively by the equations 0! = 1 and, for all n > 0, n! = n(n - 1)!. Neither equation by\nitself constitutes a complete definition; the first is the base case, and the second is the\nrecursive case. Because the base case breaks the chain of recursion, it is sometimes also called\nthe \"terminating case\".\nThe job of the recursive cases can be seen as breaking down complex inputs into simpler ones. In a\nproperly designed recursive function, with each recursive call, the input problem must be simplified\nin such a way that eventually the base case must be reached. Neglecting to write a base case, or\ntesting for it incorrectly, can cause an infinite loop.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is a base case in a recursive function?\n","icl_response_1":"It's the input where the function returns a result without calling itself, like 0! = 1 in factorial.\n","icl_query_2":"What happens in the recursive case?\n","icl_response_2":"The function calls itself with a simpler input, breaking down the problem until the base case is\nreached.\n","icl_query_3":"Why is the base case important?\n","icl_response_3":"It stops the recursion; without it, the function might cause an infinite loop.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the purpose of short-circuiting in recursion?\n\nA) It doubles the number of function calls in the worst case.\nB) It eliminates the need for a wrapper function when the tree is empty.\nC) It reduces the number of function calls by half in the worst case.\nD) It is not related to recursion in depth-first search.","mmlubench_answer":"C) It reduces the number of function calls by half in the worst case.","dataset_type":"mcq_qa","answer":2,"choices":["It doubles the number of function calls in the worst case.","It eliminates the need for a wrapper function when the tree is empty.","It reduces the number of function calls by half in the worst case.","It is not related to recursion in depth-first search."],"question":"What is the purpose of short-circuiting in recursion?"}
{"document":"Recursion_(computer_science)\nImplementation issues\nShort-circuiting the base case\n=### Depth-first search=\nA basic example of short-circuiting is given in depth-first search (DFS) of a binary tree; see binary trees section for standard recursive discussion.\nThe standard recursive algorithm for a DFS is:\nbase case: If current node is Null, return false\nrecursive step: otherwise, check value of current node, return true if match, otherwise recurse on children\nIn short-circuiting, this is instead:\ncheck value of current node, return true if match,\notherwise, on children, if not Null, then recurse.\nIn terms of the standard steps, this moves the base case check before the recursive step. Alternatively, these can be considered a different form of base case and recursive step, respectively. Note that this requires a wrapper function to handle the case when the tree itself is empty (root node is Null).\nIn the case of a perfect binary tree of height h, there are 2h+1\u22121 nodes and 2h+1 Null pointers as children (2 for each of the 2h leaves), so short-circuiting cuts the number of function calls in half in the worst case.\nIn C, the standard recursive algorithm may be implemented as:\nThe short-circuited algorithm may be implemented as:","icl_document":"A recursive function definition has one or more base cases, meaning input(s) for which the\nfunction produces a result trivially (without recurring), and one or more recursive cases, meaning\ninput(s) for which the program recurs (calls itself). For example, the factorial function can be\ndefined recursively by the equations 0! = 1 and, for all n > 0, n! = n(n - 1)!. Neither equation by\nitself constitutes a complete definition; the first is the base case, and the second is the\nrecursive case. Because the base case breaks the chain of recursion, it is sometimes also called\nthe \"terminating case\".\nThe job of the recursive cases can be seen as breaking down complex inputs into simpler ones. In a\nproperly designed recursive function, with each recursive call, the input problem must be simplified\nin such a way that eventually the base case must be reached. Neglecting to write a base case, or\ntesting for it incorrectly, can cause an infinite loop.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is a base case in a recursive function?\n","icl_response_1":"It's the input where the function returns a result without calling itself, like 0! = 1 in factorial.\n","icl_query_2":"What happens in the recursive case?\n","icl_response_2":"The function calls itself with a simpler input, breaking down the problem until the base case is\nreached.\n","icl_query_3":"Why is the base case important?\n","icl_response_3":"It stops the recursion; without it, the function might cause an infinite loop.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What happens if we apply short-circuiting to a standard recursive algorithm for depth-first search (DFS) of a binary tree?\n\nA) The number of function calls is increased by half in the worst case.\nB) The base case check and recursive step are swapped.\nC) It becomes an iterative algorithm instead of recursive.\nD) The algorithm no longer performs a depth-first search.","mmlubench_answer":"B) The base case check and recursive step are swapped.","dataset_type":"mcq_qa","answer":1,"choices":["The number of function calls is increased by half in the worst case.","The base case check and recursive step are swapped.","It becomes an iterative algorithm instead of recursive.","The algorithm no longer performs a depth-first search."],"question":"What happens if we apply short-circuiting to a standard recursive algorithm for depth-first search (DFS) of a binary tree?"}
{"document":"Recursion_(computer_science)\nImplementation issues\nShort-circuiting the base case\n=### Depth-first search=\nA basic example of short-circuiting is given in depth-first search (DFS) of a binary tree; see binary trees section for standard recursive discussion.\nThe standard recursive algorithm for a DFS is:\nbase case: If current node is Null, return false\nrecursive step: otherwise, check value of current node, return true if match, otherwise recurse on children\nIn short-circuiting, this is instead:\ncheck value of current node, return true if match,\notherwise, on children, if not Null, then recurse.\nIn terms of the standard steps, this moves the base case check before the recursive step. Alternatively, these can be considered a different form of base case and recursive step, respectively. Note that this requires a wrapper function to handle the case when the tree itself is empty (root node is Null).\nIn the case of a perfect binary tree of height h, there are 2h+1\u22121 nodes and 2h+1 Null pointers as children (2 for each of the 2h leaves), so short-circuiting cuts the number of function calls in half in the worst case.\nIn C, the standard recursive algorithm may be implemented as:\nThe short-circuited algorithm may be implemented as:","icl_document":"A recursive function definition has one or more base cases, meaning input(s) for which the\nfunction produces a result trivially (without recurring), and one or more recursive cases, meaning\ninput(s) for which the program recurs (calls itself). For example, the factorial function can be\ndefined recursively by the equations 0! = 1 and, for all n > 0, n! = n(n - 1)!. Neither equation by\nitself constitutes a complete definition; the first is the base case, and the second is the\nrecursive case. Because the base case breaks the chain of recursion, it is sometimes also called\nthe \"terminating case\".\nThe job of the recursive cases can be seen as breaking down complex inputs into simpler ones. In a\nproperly designed recursive function, with each recursive call, the input problem must be simplified\nin such a way that eventually the base case must be reached. Neglecting to write a base case, or\ntesting for it incorrectly, can cause an infinite loop.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is a base case in a recursive function?\n","icl_response_1":"It's the input where the function returns a result without calling itself, like 0! = 1 in factorial.\n","icl_query_2":"What happens in the recursive case?\n","icl_response_2":"The function calls itself with a simpler input, breaking down the problem until the base case is\nreached.\n","icl_query_3":"Why is the base case important?\n","icl_response_3":"It stops the recursion; without it, the function might cause an infinite loop.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"How does the short-circuited DFS algorithm in C differ from the standard recursive algorithm?\n\nA) It uses a loop instead of recursion.\nB) The base case check comes before the recursive step.\nC) It handles empty trees using an if statement.\nD) The order of checking value and children is reversed.","mmlubench_answer":"D) The order of checking value and children is reversed.","dataset_type":"mcq_qa","answer":3,"choices":["It uses a loop instead of recursion.","The base case check comes before the recursive step.","It handles empty trees using an if statement.","The order of checking value and children is reversed."],"question":"How does the short-circuited DFS algorithm in C differ from the standard recursive algorithm?"}
{"document":"Recursion_(computer_science)\nRecursion versus iteration\nExpressive power\nMost programming languages in use today allow the direct specification of recursive functions and procedures. When such a function is called, the program's runtime environment keeps track of the various instances of the function (often using a call stack, although other methods may be used). Every recursive function can be transformed into an iterative function by replacing recursive calls with iterative control constructs and simulating the call stack with a stack explicitly managed by the program.\nConversely, all iterative functions and procedures that can be evaluated by a computer (see Turing completeness) can be expressed in terms of recursive functions; iterative control constructs such as while loops and for loops are routinely rewritten in recursive form in functional languages. However, in practice this rewriting depends on tail call elimination, which is not a feature of all languages. C, Java, and Python are notable mainstream languages in which all function calls, including tail calls, may cause stack allocation that would not occur with the use of looping constructs; in these languages, a working iterative program rewritten in recursive form may overflow the call stack, although tail call elimination may be a feature that is not covered by a language's specification, and different implementations of the same language may differ in tail call elimination capabilities.","icl_document":"A recursive function definition has one or more base cases, meaning input(s) for which the\nfunction produces a result trivially (without recurring), and one or more recursive cases, meaning\ninput(s) for which the program recurs (calls itself). For example, the factorial function can be\ndefined recursively by the equations 0! = 1 and, for all n > 0, n! = n(n - 1)!. Neither equation by\nitself constitutes a complete definition; the first is the base case, and the second is the\nrecursive case. Because the base case breaks the chain of recursion, it is sometimes also called\nthe \"terminating case\".\nThe job of the recursive cases can be seen as breaking down complex inputs into simpler ones. In a\nproperly designed recursive function, with each recursive call, the input problem must be simplified\nin such a way that eventually the base case must be reached. Neglecting to write a base case, or\ntesting for it incorrectly, can cause an infinite loop.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is a base case in a recursive function?\n","icl_response_1":"It's the input where the function returns a result without calling itself, like 0! = 1 in factorial.\n","icl_query_2":"What happens in the recursive case?\n","icl_response_2":"The function calls itself with a simpler input, breaking down the problem until the base case is\nreached.\n","icl_query_3":"Why is the base case important?\n","icl_response_3":"It stops the recursion; without it, the function might cause an infinite loop.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"Which of the following is a difference between recursion and iteration in programming?\n\nA) Recursive functions cannot be transformed into iterative functions\nB) Iterative control constructs such as while loops and for loops cannot be expressed in terms of recursive functions\nC) Recursive functions always result in stack allocation\nD) Tail call elimination is a feature of all programming languages","mmlubench_answer":"C) Recursive functions may cause stack allocation that is not necessary with the use of looping constructs (depending on the language and its implementation)","dataset_type":"mcq_qa","answer":2,"choices":["Recursive functions cannot be transformed into iterative functions","Iterative control constructs such as while loops and for loops cannot be expressed in terms of recursive functions","Recursive functions always result in stack allocation","Tail call elimination is a feature of all programming languages"],"question":"Which of the following is a difference between recursion and iteration in programming?"}
{"document":"Recursion_(computer_science)\nRecursion versus iteration\nStack space\nIn some programming languages, the maximum size of the call stack is much less than the space available in the heap, and recursive algorithms tend to require more stack space than iterative algorithms. Consequently, these languages sometimes place a limit on the depth of recursion to avoid stack overflows; Python is one such language. Note the caveat below regarding the special case of tail recursion.","icl_document":"A recursive function definition has one or more base cases, meaning input(s) for which the\nfunction produces a result trivially (without recurring), and one or more recursive cases, meaning\ninput(s) for which the program recurs (calls itself). For example, the factorial function can be\ndefined recursively by the equations 0! = 1 and, for all n > 0, n! = n(n - 1)!. Neither equation by\nitself constitutes a complete definition; the first is the base case, and the second is the\nrecursive case. Because the base case breaks the chain of recursion, it is sometimes also called\nthe \"terminating case\".\nThe job of the recursive cases can be seen as breaking down complex inputs into simpler ones. In a\nproperly designed recursive function, with each recursive call, the input problem must be simplified\nin such a way that eventually the base case must be reached. Neglecting to write a base case, or\ntesting for it incorrectly, can cause an infinite loop.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is a base case in a recursive function?\n","icl_response_1":"It's the input where the function returns a result without calling itself, like 0! = 1 in factorial.\n","icl_query_2":"What happens in the recursive case?\n","icl_response_2":"The function calls itself with a simpler input, breaking down the problem until the base case is\nreached.\n","icl_query_3":"Why is the base case important?\n","icl_response_3":"It stops the recursion; without it, the function might cause an infinite loop.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"Which programming languages have a limit on the depth of recursion to avoid stack overflows?\n\nA) Java\nB) C++\nC) Python\nD) Ruby","mmlubench_answer":"C) Python","dataset_type":"mcq_qa","answer":2,"choices":["Java","C++","Python","Ruby"],"question":"Which programming languages have a limit on the depth of recursion to avoid stack overflows?"}
{"document":"Recursion_(computer_science)\nRecursion versus iteration\nStack space\nIn some programming languages, the maximum size of the call stack is much less than the space available in the heap, and recursive algorithms tend to require more stack space than iterative algorithms. Consequently, these languages sometimes place a limit on the depth of recursion to avoid stack overflows; Python is one such language. Note the caveat below regarding the special case of tail recursion.","icl_document":"A recursive function definition has one or more base cases, meaning input(s) for which the\nfunction produces a result trivially (without recurring), and one or more recursive cases, meaning\ninput(s) for which the program recurs (calls itself). For example, the factorial function can be\ndefined recursively by the equations 0! = 1 and, for all n > 0, n! = n(n - 1)!. Neither equation by\nitself constitutes a complete definition; the first is the base case, and the second is the\nrecursive case. Because the base case breaks the chain of recursion, it is sometimes also called\nthe \"terminating case\".\nThe job of the recursive cases can be seen as breaking down complex inputs into simpler ones. In a\nproperly designed recursive function, with each recursive call, the input problem must be simplified\nin such a way that eventually the base case must be reached. Neglecting to write a base case, or\ntesting for it incorrectly, can cause an infinite loop.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is a base case in a recursive function?\n","icl_response_1":"It's the input where the function returns a result without calling itself, like 0! = 1 in factorial.\n","icl_query_2":"What happens in the recursive case?\n","icl_response_2":"The function calls itself with a simpler input, breaking down the problem until the base case is\nreached.\n","icl_query_3":"Why is the base case important?\n","icl_response_3":"It stops the recursion; without it, the function might cause an infinite loop.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"Why does the maximum size of the call stack matter in recursive algorithms?\n\nA) Because it affects the speed of the algorithm\nB) Because it determines the depth of the recursion\nC) Because it doesn't affect recursive algorithms\nD) Because it determines the efficiency of the heap","mmlubench_answer":"B) Because it determines the depth of the recursion","dataset_type":"mcq_qa","answer":1,"choices":["Because it affects the speed of the algorithm","Because it determines the depth of the recursion","Because it doesn't affect recursive algorithms","Because it determines the efficiency of the heap"],"question":"Why does the maximum size of the call stack matter in recursive algorithms?"}
{"document":"Recursion_(computer_science)\nRecursion versus iteration\nStack space\nIn some programming languages, the maximum size of the call stack is much less than the space available in the heap, and recursive algorithms tend to require more stack space than iterative algorithms. Consequently, these languages sometimes place a limit on the depth of recursion to avoid stack overflows; Python is one such language. Note the caveat below regarding the special case of tail recursion.","icl_document":"A recursive function definition has one or more base cases, meaning input(s) for which the\nfunction produces a result trivially (without recurring), and one or more recursive cases, meaning\ninput(s) for which the program recurs (calls itself). For example, the factorial function can be\ndefined recursively by the equations 0! = 1 and, for all n > 0, n! = n(n - 1)!. Neither equation by\nitself constitutes a complete definition; the first is the base case, and the second is the\nrecursive case. Because the base case breaks the chain of recursion, it is sometimes also called\nthe \"terminating case\".\nThe job of the recursive cases can be seen as breaking down complex inputs into simpler ones. In a\nproperly designed recursive function, with each recursive call, the input problem must be simplified\nin such a way that eventually the base case must be reached. Neglecting to write a base case, or\ntesting for it incorrectly, can cause an infinite loop.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is a base case in a recursive function?\n","icl_response_1":"It's the input where the function returns a result without calling itself, like 0! = 1 in factorial.\n","icl_query_2":"What happens in the recursive case?\n","icl_response_2":"The function calls itself with a simpler input, breaking down the problem until the base case is\nreached.\n","icl_query_3":"Why is the base case important?\n","icl_response_3":"It stops the recursion; without it, the function might cause an infinite loop.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"Which type of algorithm is more memory efficient: recursive or iterative?\n\nA) Recursive algorithms require less stack space\nB) Iterative algorithms require less heap space\nC) Recursive algorithms require less memory overall\nD) Iterative algorithms require less stack space","mmlubench_answer":"D) Iterative algorithms require less stack space","dataset_type":"mcq_qa","answer":3,"choices":["Recursive algorithms require less stack space","Iterative algorithms require less heap space","Recursive algorithms require less memory overall","Iterative algorithms require less stack space"],"question":"Which type of algorithm is more memory efficient: recursive or iterative?"}
{"document":"Recursion_(computer_science)\nRecursion versus iteration\nRefactoring recursion\nRecursive algorithms can be replaced with non-recursive counterparts. One method for replacing recursive algorithms is to simulate them using heap memory in place of stack memory. An alternative is to develop a replacement algorithm entirely based on non-recursive methods, which can be challenging. For example, recursive algorithms for matching wildcards, such as Rich Salz' wildmat algorithm, were once typical. Non-recursive algorithms for the same purpose, such as the Krauss matching wildcards algorithm, have been developed to avoid the drawbacks of recursion and have improved only gradually based on techniques such as collecting tests and profiling performance.","icl_document":"Recursion that contains only a single self-reference is known as single recursion, while recursion\nthat contains multiple self-references is known as multiple recursion. Standard examples of single\nrecursion include list traversal, such as in a linear search, or computing the factorial function,\nwhile standard examples of multiple recursion include tree traversal, such as in a depth-first\nsearch.\nSingle recursion is often much more efficient than multiple recursion, and can generally be replaced\nby an iterative computation, running in linear time and requiring constant space. Multiple recursion,\nby contrast, may require exponential time and space, and is more fundamentally recursive, not being\nable to be replaced by iteration without an explicit stack.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is single recursion?\n","icl_response_1":"It's recursion with only one self-reference, like in factorial or linear search.\n","icl_query_2":"What is multiple recursion?\n","icl_response_2":"It's recursion with multiple self-references, like in tree traversal or depth-first search.\n","icl_query_3":"How do single and multiple recursion differ in efficiency?\n","icl_response_3":"Single is often more efficient and can be iterative; multiple may need more time and space.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is an alternative to using recursive algorithms for certain purposes in computer science?\n\nA) Using heap memory instead of stack memory\nB) Developing non-recursive algorithms entirely\nC) Collecting tests and profiling performance\nD) Matching wildcards using Rich Salz' algorithm","mmlubench_answer":"B) Developing non-recursive algorithms entirely","dataset_type":"mcq_qa","answer":1,"choices":["Using heap memory instead of stack memory","Developing non-recursive algorithms entirely","Collecting tests and profiling performance","Matching wildcards using Rich Salz' algorithm"],"question":"What is an alternative to using recursive algorithms for certain purposes in computer science?"}
{"document":"Recursion_(computer_science)\nRecursion versus iteration\nRefactoring recursion\nRecursive algorithms can be replaced with non-recursive counterparts. One method for replacing recursive algorithms is to simulate them using heap memory in place of stack memory. An alternative is to develop a replacement algorithm entirely based on non-recursive methods, which can be challenging. For example, recursive algorithms for matching wildcards, such as Rich Salz' wildmat algorithm, were once typical. Non-recursive algorithms for the same purpose, such as the Krauss matching wildcards algorithm, have been developed to avoid the drawbacks of recursion and have improved only gradually based on techniques such as collecting tests and profiling performance.","icl_document":"Recursion that contains only a single self-reference is known as single recursion, while recursion\nthat contains multiple self-references is known as multiple recursion. Standard examples of single\nrecursion include list traversal, such as in a linear search, or computing the factorial function,\nwhile standard examples of multiple recursion include tree traversal, such as in a depth-first\nsearch.\nSingle recursion is often much more efficient than multiple recursion, and can generally be replaced\nby an iterative computation, running in linear time and requiring constant space. Multiple recursion,\nby contrast, may require exponential time and space, and is more fundamentally recursive, not being\nable to be replaced by iteration without an explicit stack.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is single recursion?\n","icl_response_1":"It's recursion with only one self-reference, like in factorial or linear search.\n","icl_query_2":"What is multiple recursion?\n","icl_response_2":"It's recursion with multiple self-references, like in tree traversal or depth-first search.\n","icl_query_3":"How do single and multiple recursion differ in efficiency?\n","icl_response_3":"Single is often more efficient and can be iterative; multiple may need more time and space.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"Which method can be used to replace recursive algorithms that use stack memory with?\n\nA) Heap memory\nB) Loops (iteration)\nC) Non-recursive algorithms\nD) Profiling performance","mmlubench_answer":"A) Heap memory","dataset_type":"mcq_qa","answer":0,"choices":["Heap memory","Loops (iteration)","Non-recursive algorithms","Profiling performance"],"question":"Which method can be used to replace recursive algorithms that use stack memory with?"}
{"document":"Recursion_(computer_science)\nRecursion versus iteration\nRefactoring recursion\nRecursive algorithms can be replaced with non-recursive counterparts. One method for replacing recursive algorithms is to simulate them using heap memory in place of stack memory. An alternative is to develop a replacement algorithm entirely based on non-recursive methods, which can be challenging. For example, recursive algorithms for matching wildcards, such as Rich Salz' wildmat algorithm, were once typical. Non-recursive algorithms for the same purpose, such as the Krauss matching wildcards algorithm, have been developed to avoid the drawbacks of recursion and have improved only gradually based on techniques such as collecting tests and profiling performance.","icl_document":"Recursion and iteration are equally expressive: recursion can be replaced by iteration with an\nexplicit call stack, while iteration can be replaced with tail recursion. Which approach is\npreferable depends on the problem under consideration and the language used. In imperative\nprogramming, iteration is preferred, particularly for simple recursion, as it avoids the overhead\nof function calls and call stack management, but recursion is generally used for multiple recursion.\nBy contrast, in functional languages recursion is preferred, with tail recursion optimization leading\nto little overhead. Implementing an algorithm using iteration may not be easily achievable.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"Are recursion and iteration equally powerful?\n","icl_response_1":"Yes, recursion can be turned into iteration with a stack, and iteration into recursion.\n","icl_query_2":"When is iteration preferred over recursion?\n","icl_response_2":"In imperative languages for simple cases, to avoid function call overhead.\n","icl_query_3":"When is recursion preferred?\n","icl_response_3":"In functional languages or for complex problems like multiple recursion.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is one method for replacing recursive algorithms in computer science?\n\nA) Using stack memory instead of heap memory\nB) Developing non-recursive algorithms entirely based on recursive methods\nC) Simulating recursive algorithms using heap memory\nD) Collecting tests and profiling performance to improve non-recursive algorithms","mmlubench_answer":"C) Simulating recursive algorithms using heap memory","dataset_type":"mcq_qa","answer":2,"choices":["Using stack memory instead of heap memory","Developing non-recursive algorithms entirely based on recursive methods","Simulating recursive algorithms using heap memory","Collecting tests and profiling performance to improve non-recursive algorithms"],"question":"What is one method for replacing recursive algorithms in computer science?"}
{"document":"Recursion_(computer_science)\nTail-recursive functions\nTail-recursive functions are functions in which all recursive calls are tail calls and hence do not build up any deferred operations. For example, the gcd function (shown again below) is tail-recursive.  In contrast, the factorial function (also below) is not tail-recursive; because its recursive call is not in tail position, it builds up deferred multiplication operations that must be performed after the final recursive call completes.  With a compiler or interpreter that treats tail-recursive calls as jumps rather than function calls, a tail-recursive function such as gcd will execute using constant space.  Thus the program is essentially iterative, equivalent to using imperative language control structures like the \"for\" and \"while\" loops.\nThe significance of tail recursion is that when making a tail-recursive call (or any tail call), the caller's return position need not be saved on the call stack; when the recursive call returns, it will branch directly on the previously saved return position. Therefore, in languages that recognize this property of tail calls, tail recursion saves both space and time.","icl_document":"Recursion that contains only a single self-reference is known as single recursion, while recursion\nthat contains multiple self-references is known as multiple recursion. Standard examples of single\nrecursion include list traversal, such as in a linear search, or computing the factorial function,\nwhile standard examples of multiple recursion include tree traversal, such as in a depth-first\nsearch.\nSingle recursion is often much more efficient than multiple recursion, and can generally be replaced\nby an iterative computation, running in linear time and requiring constant space. Multiple recursion,\nby contrast, may require exponential time and space, and is more fundamentally recursive, not being\nable to be replaced by iteration without an explicit stack.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is single recursion?\n","icl_response_1":"It's recursion with only one self-reference, like in factorial or linear search.\n","icl_query_2":"What is multiple recursion?\n","icl_response_2":"It's recursion with multiple self-references, like in tree traversal or depth-first search.\n","icl_query_3":"How do single and multiple recursion differ in efficiency?\n","icl_response_3":"Single is often more efficient and can be iterative; multiple may need more time and space.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the main difference between a tail-recursive function and a non-tail-recursive function in recursion?\n\nA) A tail-recursive function builds up deferred operations, while a non-tail-recursive function does not.\nB) A tail-recursive function is equivalent to using \"for\" and \"while\" loops, while a non-tail-recursive function is not.\nC) A tail-recursive function saves space but not time, while a non-tail-recursive function saves both space and time.\nD) A tail-recursive function uses function calls for recursion, while a non-tail-recursive function uses jumps.","mmlubench_answer":"D) A tail-recursive function uses jumps for recursion, while a non-tail-recursive function uses function calls.","dataset_type":"mcq_qa","answer":3,"choices":["A tail-recursive function builds up deferred operations, while a non-tail-recursive function does not.","A tail-recursive function is equivalent to using \"for\" and \"while\" loops, while a non-tail-recursive function is not.","A tail-recursive function saves space but not time, while a non-tail-recursive function saves both space and time.","A tail-recursive function uses function calls for recursion, while a non-tail-recursive function uses jumps."],"question":"What is the main difference between a tail-recursive function and a non-tail-recursive function in recursion?"}
{"document":"Recursion_(computer_science)\nTail-recursive functions\nTail-recursive functions are functions in which all recursive calls are tail calls and hence do not build up any deferred operations. For example, the gcd function (shown again below) is tail-recursive.  In contrast, the factorial function (also below) is not tail-recursive; because its recursive call is not in tail position, it builds up deferred multiplication operations that must be performed after the final recursive call completes.  With a compiler or interpreter that treats tail-recursive calls as jumps rather than function calls, a tail-recursive function such as gcd will execute using constant space.  Thus the program is essentially iterative, equivalent to using imperative language control structures like the \"for\" and \"while\" loops.\nThe significance of tail recursion is that when making a tail-recursive call (or any tail call), the caller's return position need not be saved on the call stack; when the recursive call returns, it will branch directly on the previously saved return position. Therefore, in languages that recognize this property of tail calls, tail recursion saves both space and time.","icl_document":"Recursion that contains only a single self-reference is known as single recursion, while recursion\nthat contains multiple self-references is known as multiple recursion. Standard examples of single\nrecursion include list traversal, such as in a linear search, or computing the factorial function,\nwhile standard examples of multiple recursion include tree traversal, such as in a depth-first\nsearch.\nSingle recursion is often much more efficient than multiple recursion, and can generally be replaced\nby an iterative computation, running in linear time and requiring constant space. Multiple recursion,\nby contrast, may require exponential time and space, and is more fundamentally recursive, not being\nable to be replaced by iteration without an explicit stack.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is single recursion?\n","icl_response_1":"It's recursion with only one self-reference, like in factorial or linear search.\n","icl_query_2":"What is multiple recursion?\n","icl_response_2":"It's recursion with multiple self-references, like in tree traversal or depth-first search.\n","icl_query_3":"How do single and multiple recursion differ in efficiency?\n","icl_response_3":"Single is often more efficient and can be iterative; multiple may need more time and space.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the significance of tail recursion in programming?\n\nA) It allows saving both space and time during recursive function calls.\nB) It enables the use of \"for\" and \"while\" loops instead of recursive functions.\nC) It ensures that deferred operations are built up during recursive calls.\nD) It requires a specific compiler or interpreter setting to be recognized as tail-recursive.","mmlubench_answer":"A) It allows saving both space and time during recursive function calls.","dataset_type":"mcq_qa","answer":0,"choices":["It allows saving both space and time during recursive function calls.","It enables the use of \"for\" and \"while\" loops instead of recursive functions.","It ensures that deferred operations are built up during recursive calls.","It requires a specific compiler or interpreter setting to be recognized as tail-recursive."],"question":"What is the significance of tail recursion in programming?"}
{"document":"Recursion_(computer_science)\nRecursive data structures (structural recursion)\nAn important application of recursion in computer science is in defining dynamic data structures such as lists and trees.  Recursive data structures can dynamically grow to a theoretically infinite size in response to runtime requirements; in contrast, the size of a static array must be set at compile time.\n\"Recursive algorithms are particularly appropriate when the underlying problem or the data to be treated are defined in recursive terms.\"\nThe examples in this section illustrate what is known as \"structural recursion\".  This term refers to the fact that the recursive procedures are acting on data that is defined recursively.\nAs long as a programmer derives the template from a data definition, functions employ structural recursion. That is, the recursions in a function's body consume some immediate piece of a given compound value.","icl_document":"Recursion and iteration are equally expressive: recursion can be replaced by iteration with an\nexplicit call stack, while iteration can be replaced with tail recursion. Which approach is\npreferable depends on the problem under consideration and the language used. In imperative\nprogramming, iteration is preferred, particularly for simple recursion, as it avoids the overhead\nof function calls and call stack management, but recursion is generally used for multiple recursion.\nBy contrast, in functional languages recursion is preferred, with tail recursion optimization leading\nto little overhead. Implementing an algorithm using iteration may not be easily achievable.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"Are recursion and iteration equally powerful?\n","icl_response_1":"Yes, recursion can be turned into iteration with a stack, and iteration into recursion.\n","icl_query_2":"When is iteration preferred over recursion?\n","icl_response_2":"In imperative languages for simple cases, to avoid function call overhead.\n","icl_query_3":"When is recursion preferred?\n","icl_response_3":"In functional languages or for complex problems like multiple recursion.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the term used to describe the application of recursion in defining dynamic data structures in computer science?\n\nA) Procedural recursion\nB) Structural recursion (correct answer)\nC) Declarative recursion\nD) Functional recursion","mmlubench_answer":"B) Structural recursion","dataset_type":"mcq_qa","answer":1,"choices":["Procedural recursion","Structural recursion (correct answer)","Declarative recursion","Functional recursion"],"question":"What is the term used to describe the application of recursion in defining dynamic data structures in computer science?"}
{"document":"Recursion_(computer_science)\nTime-efficiency of recursive algorithms\nShortcut rule (master theorem)\nIf the time-complexity of the function is in the form\n```\nT\n    (\n    n\n    )\n    =\n    a\n    \u22c5\n    T\n    (\n    n\n    \n      \/\n    \n    b\n    )\n    +\n    f\n    (\n    n\n    )\n  \n\n{\\displaystyle T(n)=a\\cdot T(n\/b)+f(n)}\n```\nThen the Big O of the time-complexity is thus:\nIf\n```\nf\n    (\n    n\n    )\n    =\n    O\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n        \u2212\n        \u03b5\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=O(n^{\\log _{b}a-\\varepsilon })}\n```\nfor some constant\n```\n\u03b5\n    >\n    0\n  \n\n{\\displaystyle \\varepsilon >0}\n```\n, then\n```\nT\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle T(n)=\\Theta (n^{\\log _{b}a})}\n```\nIf\n```\nf\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=\\Theta (n^{\\log _{b}a})}\n```\n, then","icl_document":"In computer science, recursion is a method of solving a computational problem where the solution\ndepends on solutions to smaller instances of the same problem. Recursion solves such recursive\nproblems by using functions that call themselves from within their own code. The approach can be\napplied to many types of problems, and recursion is one of the central ideas of computer science.\nThe power of recursion evidently lies in the possibility of defining an infinite set of objects\nby a finite statement. In the same manner, an infinite number of computations can be described by\na finite recursive program, even if this program contains no explicit repetitions\nMost computer programming languages support recursion by allowing a function to call itself from\nwithin its own code. Some functional programming languages (for instance, Clojure) do not define\nany looping constructs but rely solely on recursion to repeatedly call code. It is proved in\ncomputability theory that these recursive-only languages are Turing complete; this means that\nthey are as powerful (they can be used to solve the same problems) as imperative languages based\non control structures such as while and for.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is recursion in computer science?\n","icl_response_1":"Recursion is a method where a function calls itself to solve a problem by breaking it into\nsmaller instances of the same problem.\n","icl_query_2":"Why is recursion powerful?\n","icl_response_2":"It allows defining infinite computations or objects with a finite statement, without explicit\nrepetitions.\n","icl_query_3":"Do most programming languages support recursion?\n","icl_response_3":"Yes, most allow functions to call themselves, and some rely solely on recursion instead of loops.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the formula for determining the Big O time complexity of a recursive algorithm with function T(n) and base case f(n)?\n\nA) T(n) = a\u22c5T(n\/b) + \u0398(n^log_ba)\nB) T(n) = \u0398(a\u22c5T(n\/b) + n^log_ba)\nC) T(n) = log(b)\u2061a\u22c5T(n\/b) + f(n)\nD) T(n) = a\u22c5log(b)\u2061T(n\/b) + \u0398(f(n))","mmlubench_answer":"A) T(n) = a\u22c5T(n\/b) + \u0398(n^log_ba)","dataset_type":"mcq_qa","answer":0,"choices":["T(n) = a\u22c5T(n\/b) + \u0398(n^log_ba)","T(n) = \u0398(a\u22c5T(n\/b) + n^log_ba)","T(n) = log(b)\u2061a\u22c5T(n\/b) + f(n)","T(n) = a\u22c5log(b)\u2061T(n\/b) + \u0398(f(n))"],"question":"What is the formula for determining the Big O time complexity of a recursive algorithm with function T(n) and base case f(n)?"}
{"document":"Recursion_(computer_science)\nTime-efficiency of recursive algorithms\nShortcut rule (master theorem)\nIf the time-complexity of the function is in the form\n```\nT\n    (\n    n\n    )\n    =\n    a\n    \u22c5\n    T\n    (\n    n\n    \n      \/\n    \n    b\n    )\n    +\n    f\n    (\n    n\n    )\n  \n\n{\\displaystyle T(n)=a\\cdot T(n\/b)+f(n)}\n```\nThen the Big O of the time-complexity is thus:\nIf\n```\nf\n    (\n    n\n    )\n    =\n    O\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n        \u2212\n        \u03b5\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=O(n^{\\log _{b}a-\\varepsilon })}\n```\nfor some constant\n```\n\u03b5\n    >\n    0\n  \n\n{\\displaystyle \\varepsilon >0}\n```\n, then\n```\nT\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle T(n)=\\Theta (n^{\\log _{b}a})}\n```\nIf\n```\nf\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=\\Theta (n^{\\log _{b}a})}\n```\n, then","icl_document":"In computer science, recursion is a method of solving a computational problem where the solution\ndepends on solutions to smaller instances of the same problem. Recursion solves such recursive\nproblems by using functions that call themselves from within their own code. The approach can be\napplied to many types of problems, and recursion is one of the central ideas of computer science.\nThe power of recursion evidently lies in the possibility of defining an infinite set of objects\nby a finite statement. In the same manner, an infinite number of computations can be described by\na finite recursive program, even if this program contains no explicit repetitions\nMost computer programming languages support recursion by allowing a function to call itself from\nwithin its own code. Some functional programming languages (for instance, Clojure) do not define\nany looping constructs but rely solely on recursion to repeatedly call code. It is proved in\ncomputability theory that these recursive-only languages are Turing complete; this means that\nthey are as powerful (they can be used to solve the same problems) as imperative languages based\non control structures such as while and for.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is recursion in computer science?\n","icl_response_1":"Recursion is a method where a function calls itself to solve a problem by breaking it into\nsmaller instances of the same problem.\n","icl_query_2":"Why is recursion powerful?\n","icl_response_2":"It allows defining infinite computations or objects with a finite statement, without explicit\nrepetitions.\n","icl_query_3":"Do most programming languages support recursion?\n","icl_response_3":"Yes, most allow functions to call themselves, and some rely solely on recursion instead of loops.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"If the time complexity function f(n) is Theta (n^(log_ba)), what can be determined about the Big O time complexity of a recursive algorithm?\n\nA) It is not specified by the given master theorem\nB) It is equal to \u0398(n^log_ba)\nC) Its Big O value depends on the value of 'a'\nD) The recursion tree will have a height of O(log_b n)","mmlubench_answer":"B) It is equal to \u0398(n^log_ba)","dataset_type":"mcq_qa","answer":1,"choices":["It is not specified by the given master theorem","It is equal to \u0398(n^log_ba)","Its Big O value depends on the value of 'a'","The recursion tree will have a height of O(log_b n)"],"question":"If the time complexity function f(n) is Theta (n^(log_ba)), what can be determined about the Big O time complexity of a recursive algorithm?"}
{"document":"Recursion_(computer_science)\nTime-efficiency of recursive algorithms\nShortcut rule (master theorem)\nIf the time-complexity of the function is in the form\n```\nT\n    (\n    n\n    )\n    =\n    a\n    \u22c5\n    T\n    (\n    n\n    \n      \/\n    \n    b\n    )\n    +\n    f\n    (\n    n\n    )\n  \n\n{\\displaystyle T(n)=a\\cdot T(n\/b)+f(n)}\n```\nThen the Big O of the time-complexity is thus:\nIf\n```\nf\n    (\n    n\n    )\n    =\n    O\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n        \u2212\n        \u03b5\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=O(n^{\\log _{b}a-\\varepsilon })}\n```\nfor some constant\n```\n\u03b5\n    >\n    0\n  \n\n{\\displaystyle \\varepsilon >0}\n```\n, then\n```\nT\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle T(n)=\\Theta (n^{\\log _{b}a})}\n```\nIf\n```\nf\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=\\Theta (n^{\\log _{b}a})}\n```\n, then","icl_document":"In computer science, recursion is a method of solving a computational problem where the solution\ndepends on solutions to smaller instances of the same problem. Recursion solves such recursive\nproblems by using functions that call themselves from within their own code. The approach can be\napplied to many types of problems, and recursion is one of the central ideas of computer science.\nThe power of recursion evidently lies in the possibility of defining an infinite set of objects\nby a finite statement. In the same manner, an infinite number of computations can be described by\na finite recursive program, even if this program contains no explicit repetitions\nMost computer programming languages support recursion by allowing a function to call itself from\nwithin its own code. Some functional programming languages (for instance, Clojure) do not define\nany looping constructs but rely solely on recursion to repeatedly call code. It is proved in\ncomputability theory that these recursive-only languages are Turing complete; this means that\nthey are as powerful (they can be used to solve the same problems) as imperative languages based\non control structures such as while and for.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is recursion in computer science?\n","icl_response_1":"Recursion is a method where a function calls itself to solve a problem by breaking it into\nsmaller instances of the same problem.\n","icl_query_2":"Why is recursion powerful?\n","icl_response_2":"It allows defining infinite computations or objects with a finite statement, without explicit\nrepetitions.\n","icl_query_3":"Do most programming languages support recursion?\n","icl_response_3":"Yes, most allow functions to call themselves, and some rely solely on recursion instead of loops.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"Given the master theorem, what is the Big O time complexity of a recursive algorithm with base case f(n) = O(1) and T(n) = 3T(n\/2) + n^2?\n\nA) \u0398(log n)\nB) \u0398(n^log_2 3)\nC) \u0398(n log n)\nD) \u0398(n^2)","mmlubench_answer":"A) \u0398(log n)","dataset_type":"mcq_qa","answer":0,"choices":["\u0398(log n)","\u0398(n^log_2 3)","\u0398(n log n)","\u0398(n^2)"],"question":"Given the master theorem, what is the Big O time complexity of a recursive algorithm with base case f(n) = O(1) and T(n) = 3T(n\/2) + n^2?"}
{"document":"Recursion_(computer_science)\nTime-efficiency of recursive algorithms\nShortcut rule (master theorem)\nIf the time-complexity of the function is in the form\n```\nT\n    (\n    n\n    )\n    =\n    a\n    \u22c5\n    T\n    (\n    n\n    \n      \/\n    \n    b\n    )\n    +\n    f\n    (\n    n\n    )\n  \n\n{\\displaystyle T(n)=a\\cdot T(n\/b)+f(n)}\n```\nThen the Big O of the time-complexity is thus:\nIf\n```\nf\n    (\n    n\n    )\n    =\n    O\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n        \u2212\n        \u03b5\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=O(n^{\\log _{b}a-\\varepsilon })}\n```\nfor some constant\n```\n\u03b5\n    >\n    0\n  \n\n{\\displaystyle \\varepsilon >0}\n```\n, then\n```\nT\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle T(n)=\\Theta (n^{\\log _{b}a})}\n```\nIf\n```\nf\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=\\Theta (n^{\\log _{b}a})}\n```\n, then","icl_document":"A recursive function definition has one or more base cases, meaning input(s) for which the\nfunction produces a result trivially (without recurring), and one or more recursive cases, meaning\ninput(s) for which the program recurs (calls itself). For example, the factorial function can be\ndefined recursively by the equations 0! = 1 and, for all n > 0, n! = n(n - 1)!. Neither equation by\nitself constitutes a complete definition; the first is the base case, and the second is the\nrecursive case. Because the base case breaks the chain of recursion, it is sometimes also called\nthe \"terminating case\".\nThe job of the recursive cases can be seen as breaking down complex inputs into simpler ones. In a\nproperly designed recursive function, with each recursive call, the input problem must be simplified\nin such a way that eventually the base case must be reached. Neglecting to write a base case, or\ntesting for it incorrectly, can cause an infinite loop.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is a base case in a recursive function?\n","icl_response_1":"It's the input where the function returns a result without calling itself, like 0! = 1 in factorial.\n","icl_query_2":"What happens in the recursive case?\n","icl_response_2":"The function calls itself with a simpler input, breaking down the problem until the base case is\nreached.\n","icl_query_3":"Why is the base case important?\n","icl_response_3":"It stops the recursion; without it, the function might cause an infinite loop.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the formula for determining the Big O time complexity of a recursive algorithm?\n\nA) T(n) = a\u22c5T(n\/b) + f(n\/2)\nB) T(n) = a\u22c5T(n\/b) + \u0398(log b \\* a)\nC) T(n) = a\u22c5T(n\/b) + O(log n \\* a)\nD) T(n) = a\u22c5T(n\/b) + \u0398(n^(log a \/ b))","mmlubench_answer":"D) T(n) = a\u22c5T(n\/b) + \u0398(n^(log a \/ b))","dataset_type":"mcq_qa","answer":3,"choices":["T(n) = a\u22c5T(n\/b) + f(n\/2)","T(n) = a\u22c5T(n\/b) + \u0398(log b \\* a)","T(n) = a\u22c5T(n\/b) + O(log n \\* a)","T(n) = a\u22c5T(n\/b) + \u0398(n^(log a \/ b))"],"question":"What is the formula for determining the Big O time complexity of a recursive algorithm?"}
{"document":"Recursion_(computer_science)\nTime-efficiency of recursive algorithms\nShortcut rule (master theorem)\nIf the time-complexity of the function is in the form\n```\nT\n    (\n    n\n    )\n    =\n    a\n    \u22c5\n    T\n    (\n    n\n    \n      \/\n    \n    b\n    )\n    +\n    f\n    (\n    n\n    )\n  \n\n{\\displaystyle T(n)=a\\cdot T(n\/b)+f(n)}\n```\nThen the Big O of the time-complexity is thus:\nIf\n```\nf\n    (\n    n\n    )\n    =\n    O\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n        \u2212\n        \u03b5\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=O(n^{\\log _{b}a-\\varepsilon })}\n```\nfor some constant\n```\n\u03b5\n    >\n    0\n  \n\n{\\displaystyle \\varepsilon >0}\n```\n, then\n```\nT\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle T(n)=\\Theta (n^{\\log _{b}a})}\n```\nIf\n```\nf\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=\\Theta (n^{\\log _{b}a})}\n```\n, then","icl_document":"Recursion that contains only a single self-reference is known as single recursion, while recursion\nthat contains multiple self-references is known as multiple recursion. Standard examples of single\nrecursion include list traversal, such as in a linear search, or computing the factorial function,\nwhile standard examples of multiple recursion include tree traversal, such as in a depth-first\nsearch.\nSingle recursion is often much more efficient than multiple recursion, and can generally be replaced\nby an iterative computation, running in linear time and requiring constant space. Multiple recursion,\nby contrast, may require exponential time and space, and is more fundamentally recursive, not being\nable to be replaced by iteration without an explicit stack.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is single recursion?\n","icl_response_1":"It's recursion with only one self-reference, like in factorial or linear search.\n","icl_query_2":"What is multiple recursion?\n","icl_response_2":"It's recursion with multiple self-references, like in tree traversal or depth-first search.\n","icl_query_3":"How do single and multiple recursion differ in efficiency?\n","icl_response_3":"Single is often more efficient and can be iterative; multiple may need more time and space.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the formula for determining the Big O time complexity of a recursive algorithm, as given by the master theorem?\n\nA) T(n) = a\u22c5T(n\/b) + f(n)\nB) f(n) = O(n^logbaseb a)\nC) T(n) = \u0398(n^logbaseb a) if f(n) = O(n^logbaseba \u2212 \u03b5) for some constant \u03b5 > 0\nD) T(n) = \u0398(n^logbaseb a) if f(n) = \u0398(n^logbaseba)","mmlubench_answer":"C) T(n) = \u0398(n^logbaseb a) if f(n) = O(n^logbaseba \u2212 \u03b5) for some constant \u03b5 > 0\nD) T(n) = \u0398(n^logbaseb a) if f(n) = \u0398(n^logbaseba)","dataset_type":"mcq_qa","answer":2,"choices":["T(n) = a\u22c5T(n\/b) + f(n)","f(n) = O(n^logbaseb a)","T(n) = \u0398(n^logbaseb a) if f(n) = O(n^logbaseba \u2212 \u03b5) for some constant \u03b5 > 0","T(n) = \u0398(n^logbaseb a) if f(n) = \u0398(n^logbaseba)"],"question":"What is the formula for determining the Big O time complexity of a recursive algorithm, as given by the master theorem?"}
{"document":"Recursion_(computer_science)\nTime-efficiency of recursive algorithms\nShortcut rule (master theorem)\nIf the time-complexity of the function is in the form\n```\nT\n    (\n    n\n    )\n    =\n    a\n    \u22c5\n    T\n    (\n    n\n    \n      \/\n    \n    b\n    )\n    +\n    f\n    (\n    n\n    )\n  \n\n{\\displaystyle T(n)=a\\cdot T(n\/b)+f(n)}\n```\nThen the Big O of the time-complexity is thus:\nIf\n```\nf\n    (\n    n\n    )\n    =\n    O\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n        \u2212\n        \u03b5\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=O(n^{\\log _{b}a-\\varepsilon })}\n```\nfor some constant\n```\n\u03b5\n    >\n    0\n  \n\n{\\displaystyle \\varepsilon >0}\n```\n, then\n```\nT\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle T(n)=\\Theta (n^{\\log _{b}a})}\n```\nIf\n```\nf\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=\\Theta (n^{\\log _{b}a})}\n```\n, then","icl_document":"Recursion that contains only a single self-reference is known as single recursion, while recursion\nthat contains multiple self-references is known as multiple recursion. Standard examples of single\nrecursion include list traversal, such as in a linear search, or computing the factorial function,\nwhile standard examples of multiple recursion include tree traversal, such as in a depth-first\nsearch.\nSingle recursion is often much more efficient than multiple recursion, and can generally be replaced\nby an iterative computation, running in linear time and requiring constant space. Multiple recursion,\nby contrast, may require exponential time and space, and is more fundamentally recursive, not being\nable to be replaced by iteration without an explicit stack.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is single recursion?\n","icl_response_1":"It's recursion with only one self-reference, like in factorial or linear search.\n","icl_query_2":"What is multiple recursion?\n","icl_response_2":"It's recursion with multiple self-references, like in tree traversal or depth-first search.\n","icl_query_3":"How do single and multiple recursion differ in efficiency?\n","icl_response_3":"Single is often more efficient and can be iterative; multiple may need more time and space.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the condition for the time complexity to be Theta (n^(log\\_b a)) in the master theorem?\n\nA) T(n) = a\u22c5T(n\/b) + \u0398(n^log\\_b a)\nB) f(n) = O(n^log\\_b a)\nC) f(n) = \u0398(n^log\\_b a)\nD) T(n) = \u0398(n^log\\_b a)","mmlubench_answer":"D) T(n) = \u0398(n^log\\_b a)","dataset_type":"mcq_qa","answer":3,"choices":["T(n) = a\u22c5T(n\/b) + \u0398(n^log\\_b a)","f(n) = O(n^log\\_b a)","f(n) = \u0398(n^log\\_b a)","T(n) = \u0398(n^log\\_b a)"],"question":"What is the condition for the time complexity to be Theta (n^(log\\_b a)) in the master theorem?"}
{"document":"Recursion_(computer_science)\nTime-efficiency of recursive algorithms\nShortcut rule (master theorem)\nIf the time-complexity of the function is in the form\n```\nT\n    (\n    n\n    )\n    =\n    a\n    \u22c5\n    T\n    (\n    n\n    \n      \/\n    \n    b\n    )\n    +\n    f\n    (\n    n\n    )\n  \n\n{\\displaystyle T(n)=a\\cdot T(n\/b)+f(n)}\n```\nThen the Big O of the time-complexity is thus:\nIf\n```\nf\n    (\n    n\n    )\n    =\n    O\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n        \u2212\n        \u03b5\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=O(n^{\\log _{b}a-\\varepsilon })}\n```\nfor some constant\n```\n\u03b5\n    >\n    0\n  \n\n{\\displaystyle \\varepsilon >0}\n```\n, then\n```\nT\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle T(n)=\\Theta (n^{\\log _{b}a})}\n```\nIf\n```\nf\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=\\Theta (n^{\\log _{b}a})}\n```\n, then","icl_document":"Recursion that contains only a single self-reference is known as single recursion, while recursion\nthat contains multiple self-references is known as multiple recursion. Standard examples of single\nrecursion include list traversal, such as in a linear search, or computing the factorial function,\nwhile standard examples of multiple recursion include tree traversal, such as in a depth-first\nsearch.\nSingle recursion is often much more efficient than multiple recursion, and can generally be replaced\nby an iterative computation, running in linear time and requiring constant space. Multiple recursion,\nby contrast, may require exponential time and space, and is more fundamentally recursive, not being\nable to be replaced by iteration without an explicit stack.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is single recursion?\n","icl_response_1":"It's recursion with only one self-reference, like in factorial or linear search.\n","icl_query_2":"What is multiple recursion?\n","icl_response_2":"It's recursion with multiple self-references, like in tree traversal or depth-first search.\n","icl_query_3":"How do single and multiple recursion differ in efficiency?\n","icl_response_3":"Single is often more efficient and can be iterative; multiple may need more time and space.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"Which part of the recursive algorithm's time complexity represents the function f(n)?\n\nA) The base case\nB) The recursive call\nC) The constant term\nD) The coefficient 'a' and log base b","mmlubench_answer":"B) The recursive call","dataset_type":"mcq_qa","answer":1,"choices":["The base case","The recursive call","The constant term","The coefficient 'a' and log base b"],"question":"Which part of the recursive algorithm's time complexity represents the function f(n)?"}
{"document":"Recursion_(computer_science)\nTime-efficiency of recursive algorithms\nShortcut rule (master theorem)\nIf the time-complexity of the function is in the form\n```\nT\n    (\n    n\n    )\n    =\n    a\n    \u22c5\n    T\n    (\n    n\n    \n      \/\n    \n    b\n    )\n    +\n    f\n    (\n    n\n    )\n  \n\n{\\displaystyle T(n)=a\\cdot T(n\/b)+f(n)}\n```\nThen the Big O of the time-complexity is thus:\nIf\n```\nf\n    (\n    n\n    )\n    =\n    O\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n        \u2212\n        \u03b5\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=O(n^{\\log _{b}a-\\varepsilon })}\n```\nfor some constant\n```\n\u03b5\n    >\n    0\n  \n\n{\\displaystyle \\varepsilon >0}\n```\n, then\n```\nT\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle T(n)=\\Theta (n^{\\log _{b}a})}\n```\nIf\n```\nf\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=\\Theta (n^{\\log _{b}a})}\n```\n, then","icl_document":"Recursion and iteration are equally expressive: recursion can be replaced by iteration with an\nexplicit call stack, while iteration can be replaced with tail recursion. Which approach is\npreferable depends on the problem under consideration and the language used. In imperative\nprogramming, iteration is preferred, particularly for simple recursion, as it avoids the overhead\nof function calls and call stack management, but recursion is generally used for multiple recursion.\nBy contrast, in functional languages recursion is preferred, with tail recursion optimization leading\nto little overhead. Implementing an algorithm using iteration may not be easily achievable.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"Are recursion and iteration equally powerful?\n","icl_response_1":"Yes, recursion can be turned into iteration with a stack, and iteration into recursion.\n","icl_query_2":"When is iteration preferred over recursion?\n","icl_response_2":"In imperative languages for simple cases, to avoid function call overhead.\n","icl_query_3":"When is recursion preferred?\n","icl_response_3":"In functional languages or for complex problems like multiple recursion.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the formula for determining the Big O time complexity of a recursive algorithm, given by T(n) = a\u22c5T(n\/b) + f(n)?\n\nA) T(n) = \u0398 (n^log b a) if f(n) = O(n^(log ba)) and b > a\nB) T(n) = \u0398 (n^log a b) if f(n) = \u0398 (n^(log ba)) and b > a\nC) T(n) = \u0398 (n^log a \/ log b) if f(n) = O(1)\nD) T(n) = \u0398 (n^log b \/ log a) if f(n) = \u0398 (n^(log ba)) and b < a","mmlubench_answer":"A) T(n) = \u0398 (n^log b a) if f(n) = O(n^(log ba)) and b > a","dataset_type":"mcq_qa","answer":0,"choices":["T(n) = \u0398 (n^log b a) if f(n) = O(n^(log ba)) and b > a","T(n) = \u0398 (n^log a b) if f(n) = \u0398 (n^(log ba)) and b > a","T(n) = \u0398 (n^log a \/ log b) if f(n) = O(1)","T(n) = \u0398 (n^log b \/ log a) if f(n) = \u0398 (n^(log ba)) and b < a"],"question":"What is the formula for determining the Big O time complexity of a recursive algorithm, given by T(n) = a\u22c5T(n\/b) + f(n)?"}
{"document":"Recursion_(computer_science)\nTime-efficiency of recursive algorithms\nShortcut rule (master theorem)\nIf the time-complexity of the function is in the form\n```\nT\n    (\n    n\n    )\n    =\n    a\n    \u22c5\n    T\n    (\n    n\n    \n      \/\n    \n    b\n    )\n    +\n    f\n    (\n    n\n    )\n  \n\n{\\displaystyle T(n)=a\\cdot T(n\/b)+f(n)}\n```\nThen the Big O of the time-complexity is thus:\nIf\n```\nf\n    (\n    n\n    )\n    =\n    O\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n        \u2212\n        \u03b5\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=O(n^{\\log _{b}a-\\varepsilon })}\n```\nfor some constant\n```\n\u03b5\n    >\n    0\n  \n\n{\\displaystyle \\varepsilon >0}\n```\n, then\n```\nT\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle T(n)=\\Theta (n^{\\log _{b}a})}\n```\nIf\n```\nf\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=\\Theta (n^{\\log _{b}a})}\n```\n, then","icl_document":"Recursion and iteration are equally expressive: recursion can be replaced by iteration with an\nexplicit call stack, while iteration can be replaced with tail recursion. Which approach is\npreferable depends on the problem under consideration and the language used. In imperative\nprogramming, iteration is preferred, particularly for simple recursion, as it avoids the overhead\nof function calls and call stack management, but recursion is generally used for multiple recursion.\nBy contrast, in functional languages recursion is preferred, with tail recursion optimization leading\nto little overhead. Implementing an algorithm using iteration may not be easily achievable.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"Are recursion and iteration equally powerful?\n","icl_response_1":"Yes, recursion can be turned into iteration with a stack, and iteration into recursion.\n","icl_query_2":"When is iteration preferred over recursion?\n","icl_response_2":"In imperative languages for simple cases, to avoid function call overhead.\n","icl_query_3":"When is recursion preferred?\n","icl_response_3":"In functional languages or for complex problems like multiple recursion.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"If the time complexity of a recursive algorithm is given by T(n) = 2\u22c5T(n\/3) + O(1), what is its Big O time complexity?\n\nA) \u0398 (n^log 3 2)\nB) \u0398 (n^log 2 3)\nC) \u0398 (n)\nD) \u0398 (log n)","mmlubench_answer":"A) \u0398 (n^(log 3 2))","dataset_type":"mcq_qa","answer":0,"choices":["\u0398 (n^log 3 2)","\u0398 (n^log 2 3)","\u0398 (n)","\u0398 (log n)"],"question":"If the time complexity of a recursive algorithm is given by T(n) = 2\u22c5T(n\/3) + O(1), what is its Big O time complexity?"}
{"document":"Recursion_(computer_science)\nTime-efficiency of recursive algorithms\nShortcut rule (master theorem)\nIf the time-complexity of the function is in the form\n```\nT\n    (\n    n\n    )\n    =\n    a\n    \u22c5\n    T\n    (\n    n\n    \n      \/\n    \n    b\n    )\n    +\n    f\n    (\n    n\n    )\n  \n\n{\\displaystyle T(n)=a\\cdot T(n\/b)+f(n)}\n```\nThen the Big O of the time-complexity is thus:\nIf\n```\nf\n    (\n    n\n    )\n    =\n    O\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n        \u2212\n        \u03b5\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=O(n^{\\log _{b}a-\\varepsilon })}\n```\nfor some constant\n```\n\u03b5\n    >\n    0\n  \n\n{\\displaystyle \\varepsilon >0}\n```\n, then\n```\nT\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle T(n)=\\Theta (n^{\\log _{b}a})}\n```\nIf\n```\nf\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=\\Theta (n^{\\log _{b}a})}\n```\n, then","icl_document":"Recursion and iteration are equally expressive: recursion can be replaced by iteration with an\nexplicit call stack, while iteration can be replaced with tail recursion. Which approach is\npreferable depends on the problem under consideration and the language used. In imperative\nprogramming, iteration is preferred, particularly for simple recursion, as it avoids the overhead\nof function calls and call stack management, but recursion is generally used for multiple recursion.\nBy contrast, in functional languages recursion is preferred, with tail recursion optimization leading\nto little overhead. Implementing an algorithm using iteration may not be easily achievable.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"Are recursion and iteration equally powerful?\n","icl_response_1":"Yes, recursion can be turned into iteration with a stack, and iteration into recursion.\n","icl_query_2":"When is iteration preferred over recursion?\n","icl_response_2":"In imperative languages for simple cases, to avoid function call overhead.\n","icl_query_3":"When is recursion preferred?\n","icl_response_3":"In functional languages or for complex problems like multiple recursion.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the condition for using the master theorem to determine the Big O time complexity of a recursive algorithm?\n\nA) The function must have a constant base case.\nB) The function must be in the form T(n) = a\u22c5T(n\/b) + f(n).\nC) The function must be monotonic and increasing.\nD) All of the above.","mmlubench_answer":"D) All of the above.","dataset_type":"mcq_qa","answer":3,"choices":["The function must have a constant base case.","The function must be in the form T(n) = a\u22c5T(n\/b) + f(n).","The function must be monotonic and increasing.","All of the above."],"question":"What is the condition for using the master theorem to determine the Big O time complexity of a recursive algorithm?"}
{"document":"Recursion_(computer_science)\nTime-efficiency of recursive algorithms\nShortcut rule (master theorem)\nIf the time-complexity of the function is in the form\n```\nT\n    (\n    n\n    )\n    =\n    a\n    \u22c5\n    T\n    (\n    n\n    \n      \/\n    \n    b\n    )\n    +\n    f\n    (\n    n\n    )\n  \n\n{\\displaystyle T(n)=a\\cdot T(n\/b)+f(n)}\n```\nThen the Big O of the time-complexity is thus:\nIf\n```\nf\n    (\n    n\n    )\n    =\n    O\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n        \u2212\n        \u03b5\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=O(n^{\\log _{b}a-\\varepsilon })}\n```\nfor some constant\n```\n\u03b5\n    >\n    0\n  \n\n{\\displaystyle \\varepsilon >0}\n```\n, then\n```\nT\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle T(n)=\\Theta (n^{\\log _{b}a})}\n```\nIf\n```\nf\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=\\Theta (n^{\\log _{b}a})}\n```\n, then","icl_document":"Recursion and iteration are equally expressive: recursion can be replaced by iteration with an\nexplicit call stack, while iteration can be replaced with tail recursion. Which approach is\npreferable depends on the problem under consideration and the language used. In imperative\nprogramming, iteration is preferred, particularly for simple recursion, as it avoids the overhead\nof function calls and call stack management, but recursion is generally used for multiple recursion.\nBy contrast, in functional languages recursion is preferred, with tail recursion optimization leading\nto little overhead. Implementing an algorithm using iteration may not be easily achievable.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"Are recursion and iteration equally powerful?\n","icl_response_1":"Yes, recursion can be turned into iteration with a stack, and iteration into recursion.\n","icl_query_2":"When is iteration preferred over recursion?\n","icl_response_2":"In imperative languages for simple cases, to avoid function call overhead.\n","icl_query_3":"When is recursion preferred?\n","icl_response_3":"In functional languages or for complex problems like multiple recursion.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the time complexity of a recursive algorithm if T(n) = 3\u22c5T(n\/2) + O(1)?\n\nA) \u0398 (log n)\nB) \u0398 (n^2)\nC) \u0398 (n)\nD) \u0398 (n^log 2 3)","mmlubench_answer":"A) \u0398 (log n)","dataset_type":"mcq_qa","answer":0,"choices":["\u0398 (log n)","\u0398 (n^2)","\u0398 (n)","\u0398 (n^log 2 3)"],"question":"What is the time complexity of a recursive algorithm if T(n) = 3\u22c5T(n\/2) + O(1)?"}
{"document":"Recursion_(computer_science)\nTime-efficiency of recursive algorithms\nShortcut rule (master theorem)\nIf the time-complexity of the function is in the form\n```\nT\n    (\n    n\n    )\n    =\n    a\n    \u22c5\n    T\n    (\n    n\n    \n      \/\n    \n    b\n    )\n    +\n    f\n    (\n    n\n    )\n  \n\n{\\displaystyle T(n)=a\\cdot T(n\/b)+f(n)}\n```\nThen the Big O of the time-complexity is thus:\nIf\n```\nf\n    (\n    n\n    )\n    =\n    O\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n        \u2212\n        \u03b5\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=O(n^{\\log _{b}a-\\varepsilon })}\n```\nfor some constant\n```\n\u03b5\n    >\n    0\n  \n\n{\\displaystyle \\varepsilon >0}\n```\n, then\n```\nT\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle T(n)=\\Theta (n^{\\log _{b}a})}\n```\nIf\n```\nf\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=\\Theta (n^{\\log _{b}a})}\n```\n, then","icl_document":"Recursion and iteration are equally expressive: recursion can be replaced by iteration with an\nexplicit call stack, while iteration can be replaced with tail recursion. Which approach is\npreferable depends on the problem under consideration and the language used. In imperative\nprogramming, iteration is preferred, particularly for simple recursion, as it avoids the overhead\nof function calls and call stack management, but recursion is generally used for multiple recursion.\nBy contrast, in functional languages recursion is preferred, with tail recursion optimization leading\nto little overhead. Implementing an algorithm using iteration may not be easily achievable.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"Are recursion and iteration equally powerful?\n","icl_response_1":"Yes, recursion can be turned into iteration with a stack, and iteration into recursion.\n","icl_query_2":"When is iteration preferred over recursion?\n","icl_response_2":"In imperative languages for simple cases, to avoid function call overhead.\n","icl_query_3":"When is recursion preferred?\n","icl_response_3":"In functional languages or for complex problems like multiple recursion.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the Big O time complexity of a recursive algorithm if T(n) = 4\u22c5T(n\/5) + O(1)?\n\nA) \u0398 (n^(log 5 4))\nB) \u0398 (n^2)\nC) \u0398 (n^(log 4 5))\nD) \u0398 (n)","mmlubench_answer":"A) \u0398 (n^(log 5 4))","dataset_type":"mcq_qa","answer":0,"choices":["\u0398 (n^(log 5 4))","\u0398 (n^2)","\u0398 (n^(log 4 5))","\u0398 (n)"],"question":"What is the Big O time complexity of a recursive algorithm if T(n) = 4\u22c5T(n\/5) + O(1)?"}
{"document":"Recursion_(computer_science)\nTime-efficiency of recursive algorithms\nShortcut rule (master theorem)\nIf the time-complexity of the function is in the form\n```\nT\n    (\n    n\n    )\n    =\n    a\n    \u22c5\n    T\n    (\n    n\n    \n      \/\n    \n    b\n    )\n    +\n    f\n    (\n    n\n    )\n  \n\n{\\displaystyle T(n)=a\\cdot T(n\/b)+f(n)}\n```\nThen the Big O of the time-complexity is thus:\nIf\n```\nf\n    (\n    n\n    )\n    =\n    O\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n        \u2212\n        \u03b5\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=O(n^{\\log _{b}a-\\varepsilon })}\n```\nfor some constant\n```\n\u03b5\n    >\n    0\n  \n\n{\\displaystyle \\varepsilon >0}\n```\n, then\n```\nT\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle T(n)=\\Theta (n^{\\log _{b}a})}\n```\nIf\n```\nf\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=\\Theta (n^{\\log _{b}a})}\n```\n, then","icl_document":"Recursion and iteration are equally expressive: recursion can be replaced by iteration with an\nexplicit call stack, while iteration can be replaced with tail recursion. Which approach is\npreferable depends on the problem under consideration and the language used. In imperative\nprogramming, iteration is preferred, particularly for simple recursion, as it avoids the overhead\nof function calls and call stack management, but recursion is generally used for multiple recursion.\nBy contrast, in functional languages recursion is preferred, with tail recursion optimization leading\nto little overhead. Implementing an algorithm using iteration may not be easily achievable.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"Are recursion and iteration equally powerful?\n","icl_response_1":"Yes, recursion can be turned into iteration with a stack, and iteration into recursion.\n","icl_query_2":"When is iteration preferred over recursion?\n","icl_response_2":"In imperative languages for simple cases, to avoid function call overhead.\n","icl_query_3":"When is recursion preferred?\n","icl_response_3":"In functional languages or for complex problems like multiple recursion.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"If the time complexity of a recursive algorithm is given by T(n) = a\u22c5T(n\/b) + f(n), where a = 3 and b = 2, what is its Big O time complexity if f(n) = O(1)?\n\nA) \u0398 (n^2)\nB) \u0398 (n^(log 2 3))\nC) \u0398 (n^3)\nD) \u0398 (n)","mmlubench_answer":"B) \u0398 (n^(log 2 3))","dataset_type":"mcq_qa","answer":1,"choices":["\u0398 (n^2)","\u0398 (n^(log 2 3))","\u0398 (n^3)","\u0398 (n)"],"question":"If the time complexity of a recursive algorithm is given by T(n) = a\u22c5T(n\/b) + f(n), where a = 3 and b = 2, what is its Big O time complexity if f(n) = O(1)?"}
{"document":"Recursion_(computer_science)\nTime-efficiency of recursive algorithms\nShortcut rule (master theorem)\nIf the time-complexity of the function is in the form\n```\nT\n    (\n    n\n    )\n    =\n    a\n    \u22c5\n    T\n    (\n    n\n    \n      \/\n    \n    b\n    )\n    +\n    f\n    (\n    n\n    )\n  \n\n{\\displaystyle T(n)=a\\cdot T(n\/b)+f(n)}\n```\nThen the Big O of the time-complexity is thus:\nIf\n```\nf\n    (\n    n\n    )\n    =\n    O\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n        \u2212\n        \u03b5\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=O(n^{\\log _{b}a-\\varepsilon })}\n```\nfor some constant\n```\n\u03b5\n    >\n    0\n  \n\n{\\displaystyle \\varepsilon >0}\n```\n, then\n```\nT\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle T(n)=\\Theta (n^{\\log _{b}a})}\n```\nIf\n```\nf\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=\\Theta (n^{\\log _{b}a})}\n```\n, then","icl_document":"A classic example of a recursive procedure is the function used to calculate the factorial of a\nnatural number:\nfact(n) = { 1 if n=0; n \u00b7 fact(n-1) if n>0 }\nThe function can also be written as a recurrence relation:\nb_n = n b_{n-1}\nb_0 = 1\nThis factorial function can also be described without using recursion by making use of the typical\nlooping constructs found in imperative programming languages.\nThe imperative code is equivalent to a mathematical definition using an accumulator variable.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"How is factorial defined recursively?\n","icl_response_1":"fact(n) = 1 if n=0, else n * fact(n-1).\n","icl_query_2":"What is the base case in factorial?\n","icl_response_2":"When n=0, fact(0)=1.\n","icl_query_3":"Can factorial be done without recursion?\n","icl_response_3":"Yes, using loops in imperative languages.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the formula for determining the Big O time complexity of a recursive function?\n\nA) T(n) = a\u22c5T(n\/b) + f(n\/log b)\nB) T(n) = log b\u22c5T(n\/a) + f(n)\nC) T(n) = a\u22c5T(n\/b) + f(n)\nD) T(n) = log b\u22c5T(n\/a) + \u0398(n^(log ba))","mmlubench_answer":"C) T(n) = a\u22c5T(n\/b) + f(n)","dataset_type":"mcq_qa","answer":2,"choices":["T(n) = a\u22c5T(n\/b) + f(n\/log b)","T(n) = log b\u22c5T(n\/a) + f(n)","T(n) = a\u22c5T(n\/b) + f(n)","T(n) = log b\u22c5T(n\/a) + \u0398(n^(log ba))"],"question":"What is the formula for determining the Big O time complexity of a recursive function?"}
{"document":"Recursion_(computer_science)\nTime-efficiency of recursive algorithms\nShortcut rule (master theorem)\nIf the time-complexity of the function is in the form\n```\nT\n    (\n    n\n    )\n    =\n    a\n    \u22c5\n    T\n    (\n    n\n    \n      \/\n    \n    b\n    )\n    +\n    f\n    (\n    n\n    )\n  \n\n{\\displaystyle T(n)=a\\cdot T(n\/b)+f(n)}\n```\nThen the Big O of the time-complexity is thus:\nIf\n```\nf\n    (\n    n\n    )\n    =\n    O\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n        \u2212\n        \u03b5\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=O(n^{\\log _{b}a-\\varepsilon })}\n```\nfor some constant\n```\n\u03b5\n    >\n    0\n  \n\n{\\displaystyle \\varepsilon >0}\n```\n, then\n```\nT\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle T(n)=\\Theta (n^{\\log _{b}a})}\n```\nIf\n```\nf\n    (\n    n\n    )\n    =\n    \u0398\n    (\n    \n      n\n      \n        \n          log\n          \n            b\n          \n        \n        \u2061\n        a\n      \n    \n    )\n  \n\n{\\displaystyle f(n)=\\Theta (n^{\\log _{b}a})}\n```\n, then","icl_document":"A classic example of a recursive procedure is the function used to calculate the factorial of a\nnatural number:\nfact(n) = { 1 if n=0; n \u00b7 fact(n-1) if n>0 }\nThe function can also be written as a recurrence relation:\nb_n = n b_{n-1}\nb_0 = 1\nThis factorial function can also be described without using recursion by making use of the typical\nlooping constructs found in imperative programming languages.\nThe imperative code is equivalent to a mathematical definition using an accumulator variable.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"How is factorial defined recursively?\n","icl_response_1":"fact(n) = 1 if n=0, else n * fact(n-1).\n","icl_query_2":"What is the base case in factorial?\n","icl_response_2":"When n=0, fact(0)=1.\n","icl_query_3":"Can factorial be done without recursion?\n","icl_response_3":"Yes, using loops in imperative languages.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the condition for the Big O time complexity of a recursive function to be \u0398(n^(log base b a))?\n\nA) f(n) = O(n^(log ba)) and a > \u03b5 > 0\nB) f(n) = \u0398(n^(log ba)) and a > \u03b5 > 0\nC) f(n) = \u0398(n^(log ba)) and a = \u03b5 > 0\nD) f(n) = O(n^(log ba)) and a = \u03b5 > 0","mmlubench_answer":"B) f(n) = \u0398(n^(log ba)) and a > \u03b5 > 0","dataset_type":"mcq_qa","answer":1,"choices":["f(n) = O(n^(log ba)) and a > \u03b5 > 0","f(n) = \u0398(n^(log ba)) and a > \u03b5 > 0","f(n) = \u0398(n^(log ba)) and a = \u03b5 > 0","f(n) = O(n^(log ba)) and a = \u03b5 > 0"],"question":"What is the condition for the Big O time complexity of a recursive function to be \u0398(n^(log base b a))?"}
{"document":"Recursion_(computer_science)\nRecursion in Logic Programming\nThe logical reading frees the reader from needing to know how the clause is used to solve problems. The clause can be used top-down, as in Prolog, to reduce problems to subproblems. Or it can be used bottom-up (or forwards), as in Datalog, to derive conclusions from conditions. This separation of concerns is a form of abstraction, which separates declarative knowledge from problem solving methods (see Algorithm#Algorithm = Logic + Control).","icl_document":"Recursion that contains only a single self-reference is known as single recursion, while recursion\nthat contains multiple self-references is known as multiple recursion. Standard examples of single\nrecursion include list traversal, such as in a linear search, or computing the factorial function,\nwhile standard examples of multiple recursion include tree traversal, such as in a depth-first\nsearch.\nSingle recursion is often much more efficient than multiple recursion, and can generally be replaced\nby an iterative computation, running in linear time and requiring constant space. Multiple recursion,\nby contrast, may require exponential time and space, and is more fundamentally recursive, not being\nable to be replaced by iteration without an explicit stack.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is single recursion?\n","icl_response_1":"It's recursion with only one self-reference, like in factorial or linear search.\n","icl_query_2":"What is multiple recursion?\n","icl_response_2":"It's recursion with multiple self-references, like in tree traversal or depth-first search.\n","icl_query_3":"How do single and multiple recursion differ in efficiency?\n","icl_response_3":"Single is often more efficient and can be iterative; multiple may need more time and space.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the logical reading of recursion used for in Logic Programming?\n\nA) To define problem-solving methods\nB) To separate declarative knowledge from problem-solving methods\nC) To derive conclusions from conditions\nD) To reduce problems to subproblems","mmlubench_answer":"B) To separate declarative knowledge from problem-solving methods","dataset_type":"mcq_qa","answer":1,"choices":["To define problem-solving methods","To separate declarative knowledge from problem-solving methods","To derive conclusions from conditions","To reduce problems to subproblems"],"question":"What is the logical reading of recursion used for in Logic Programming?"}
{"document":"Recursion_(computer_science)\nRecursion in Logic Programming\nThe logical reading frees the reader from needing to know how the clause is used to solve problems. The clause can be used top-down, as in Prolog, to reduce problems to subproblems. Or it can be used bottom-up (or forwards), as in Datalog, to derive conclusions from conditions. This separation of concerns is a form of abstraction, which separates declarative knowledge from problem solving methods (see Algorithm#Algorithm = Logic + Control).","icl_document":"Recursion that contains only a single self-reference is known as single recursion, while recursion\nthat contains multiple self-references is known as multiple recursion. Standard examples of single\nrecursion include list traversal, such as in a linear search, or computing the factorial function,\nwhile standard examples of multiple recursion include tree traversal, such as in a depth-first\nsearch.\nSingle recursion is often much more efficient than multiple recursion, and can generally be replaced\nby an iterative computation, running in linear time and requiring constant space. Multiple recursion,\nby contrast, may require exponential time and space, and is more fundamentally recursive, not being\nable to be replaced by iteration without an explicit stack.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is single recursion?\n","icl_response_1":"It's recursion with only one self-reference, like in factorial or linear search.\n","icl_query_2":"What is multiple recursion?\n","icl_response_2":"It's recursion with multiple self-references, like in tree traversal or depth-first search.\n","icl_query_3":"How do single and multiple recursion differ in efficiency?\n","icl_response_3":"Single is often more efficient and can be iterative; multiple may need more time and space.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"In Logic Programming, how can recursion be used in the logical reading?\n\nA) Only for defining problem-solving methods\nB) Only for separating declarative knowledge from problem-solving methods\nC) Both for defining problem-solving methods and separating declarative knowledge from problem-solving methods\nD) Neither for defining problem-solving methods nor for separating declarative knowledge from problem-solving methods","mmlubench_answer":"C) Both for defining problem-solving methods and separating declarative knowledge from problem-solving methods","dataset_type":"mcq_qa","answer":2,"choices":["Only for defining problem-solving methods","Only for separating declarative knowledge from problem-solving methods","Both for defining problem-solving methods and separating declarative knowledge from problem-solving methods","Neither for defining problem-solving methods nor for separating declarative knowledge from problem-solving methods"],"question":"In Logic Programming, how can recursion be used in the logical reading?"}
{"document":"Recursion_(computer_science)\nRecursion in Logic Programming\nThe logical reading frees the reader from needing to know how the clause is used to solve problems. The clause can be used top-down, as in Prolog, to reduce problems to subproblems. Or it can be used bottom-up (or forwards), as in Datalog, to derive conclusions from conditions. This separation of concerns is a form of abstraction, which separates declarative knowledge from problem solving methods (see Algorithm#Algorithm = Logic + Control).","icl_document":"Recursion that contains only a single self-reference is known as single recursion, while recursion\nthat contains multiple self-references is known as multiple recursion. Standard examples of single\nrecursion include list traversal, such as in a linear search, or computing the factorial function,\nwhile standard examples of multiple recursion include tree traversal, such as in a depth-first\nsearch.\nSingle recursion is often much more efficient than multiple recursion, and can generally be replaced\nby an iterative computation, running in linear time and requiring constant space. Multiple recursion,\nby contrast, may require exponential time and space, and is more fundamentally recursive, not being\nable to be replaced by iteration without an explicit stack.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"What is single recursion?\n","icl_response_1":"It's recursion with only one self-reference, like in factorial or linear search.\n","icl_query_2":"What is multiple recursion?\n","icl_response_2":"It's recursion with multiple self-references, like in tree traversal or depth-first search.\n","icl_query_3":"How do single and multiple recursion differ in efficiency?\n","icl_response_3":"Single is often more efficient and can be iterative; multiple may need more time and space.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the significance of recursion in Logic Programming when used in the logical reading?\n\nA) It allows for the solution of complex problems using simple rules\nB) It enables the separation of declarative knowledge from problem-solving methods\nC) It defines how a clause can be used to solve problems\nD) It determines the order in which subproblems are solved","mmlubench_answer":"B) It enables the separation of declarative knowledge from problem-solving methods","dataset_type":"mcq_qa","answer":1,"choices":["It allows for the solution of complex problems using simple rules","It enables the separation of declarative knowledge from problem-solving methods","It defines how a clause can be used to solve problems","It determines the order in which subproblems are solved"],"question":"What is the significance of recursion in Logic Programming when used in the logical reading?"}
{"document":"Recursion_(computer_science)\nRecursion in Logic Programming\nThe logical reading frees the reader from needing to know how the clause is used to solve problems. The clause can be used top-down, as in Prolog, to reduce problems to subproblems. Or it can be used bottom-up (or forwards), as in Datalog, to derive conclusions from conditions. This separation of concerns is a form of abstraction, which separates declarative knowledge from problem solving methods (see Algorithm#Algorithm = Logic + Control).","icl_document":"A classic example of a recursive procedure is the function used to calculate the factorial of a\nnatural number:\nfact(n) = { 1 if n=0; n \u00b7 fact(n-1) if n>0 }\nThe function can also be written as a recurrence relation:\nb_n = n b_{n-1}\nb_0 = 1\nThis factorial function can also be described without using recursion by making use of the typical\nlooping constructs found in imperative programming languages.\nThe imperative code is equivalent to a mathematical definition using an accumulator variable.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"How is factorial defined recursively?\n","icl_response_1":"fact(n) = 1 if n=0, else n * fact(n-1).\n","icl_query_2":"What is the base case in factorial?\n","icl_response_2":"When n=0, fact(0)=1.\n","icl_query_3":"Can factorial be done without recursion?\n","icl_response_3":"Yes, using loops in imperative languages.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"What is the logical reading in recursion used for in Logic Programming?\n\nA) To define the problem-solving methods\nB) To separate declarative knowledge from problem-solving methods\nC) To reduce problems to subproblems\nD) To derive conclusions from conditions","mmlubench_answer":"B) To separate declarative knowledge from problem-solving methods","dataset_type":"mcq_qa","answer":1,"choices":["To define the problem-solving methods","To separate declarative knowledge from problem-solving methods","To reduce problems to subproblems","To derive conclusions from conditions"],"question":"What is the logical reading in recursion used for in Logic Programming?"}
{"document":"Recursion_(computer_science)\nRecursion in Logic Programming\nThe logical reading frees the reader from needing to know how the clause is used to solve problems. The clause can be used top-down, as in Prolog, to reduce problems to subproblems. Or it can be used bottom-up (or forwards), as in Datalog, to derive conclusions from conditions. This separation of concerns is a form of abstraction, which separates declarative knowledge from problem solving methods (see Algorithm#Algorithm = Logic + Control).","icl_document":"A classic example of a recursive procedure is the function used to calculate the factorial of a\nnatural number:\nfact(n) = { 1 if n=0; n \u00b7 fact(n-1) if n>0 }\nThe function can also be written as a recurrence relation:\nb_n = n b_{n-1}\nb_0 = 1\nThis factorial function can also be described without using recursion by making use of the typical\nlooping constructs found in imperative programming languages.\nThe imperative code is equivalent to a mathematical definition using an accumulator variable.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"How is factorial defined recursively?\n","icl_response_1":"fact(n) = 1 if n=0, else n * fact(n-1).\n","icl_query_2":"What is the base case in factorial?\n","icl_response_2":"When n=0, fact(0)=1.\n","icl_query_3":"Can factorial be done without recursion?\n","icl_response_3":"Yes, using loops in imperative languages.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"In which direction does the logical reading in recursion allow the reader to approach the clause?\n\nA) Top-down only\nB) Bottom-up only\nC) Both top-down and bottom-up\nD) Neither top-down nor bottom-up","mmlubench_answer":"A) Top-down only","dataset_type":"mcq_qa","answer":0,"choices":["Top-down only","Bottom-up only","Both top-down and bottom-up","Neither top-down nor bottom-up"],"question":"In which direction does the logical reading in recursion allow the reader to approach the clause?"}
{"document":"Recursion_(computer_science)\nRecursion in Logic Programming\nThe logical reading frees the reader from needing to know how the clause is used to solve problems. The clause can be used top-down, as in Prolog, to reduce problems to subproblems. Or it can be used bottom-up (or forwards), as in Datalog, to derive conclusions from conditions. This separation of concerns is a form of abstraction, which separates declarative knowledge from problem solving methods (see Algorithm#Algorithm = Logic + Control).","icl_document":"A classic example of a recursive procedure is the function used to calculate the factorial of a\nnatural number:\nfact(n) = { 1 if n=0; n \u00b7 fact(n-1) if n>0 }\nThe function can also be written as a recurrence relation:\nb_n = n b_{n-1}\nb_0 = 1\nThis factorial function can also be described without using recursion by making use of the typical\nlooping constructs found in imperative programming languages.\nThe imperative code is equivalent to a mathematical definition using an accumulator variable.\n","document_outline":"Recursion in computer science, covering its definition, characteristics, types, and practical examples\nlike factorial and binary search.\n","subject":"computer_science","leaf_node_type":"knowledge","icl_query_1":"How is factorial defined recursively?\n","icl_response_1":"fact(n) = 1 if n=0, else n * fact(n-1).\n","icl_query_2":"What is the base case in factorial?\n","icl_response_2":"When n=0, fact(0)=1.\n","icl_query_3":"Can factorial be done without recursion?\n","icl_response_3":"Yes, using loops in imperative languages.\n","leaf_node_path":"knowledge_technology_computer_science_programming_paradigms_functional_recursion","mmlubench_question":"Which programming approach uses the logical reading to reduce problems to subproblems?\n\nA) Prolog\nB) Datalog\nC) Logic Programming\nD) Algorithm","mmlubench_answer":"A) Prolog","dataset_type":"mcq_qa","answer":0,"choices":["Prolog","Datalog","Logic Programming","Algorithm"],"question":"Which programming approach uses the logical reading to reduce problems to subproblems?"}
